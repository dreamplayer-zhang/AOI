{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet50.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76HprlF9MP8g",
        "outputId": "d5df0b79-f5d3-49e8-b284-158b6346b6b1"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jan 21 00:04:47 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJbQOiCsMbHM",
        "outputId": "6ea88e46-54a3-46ff-9be0-2acc86e1948d"
      },
      "source": [
        "import os\r\n",
        "\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us87D8ybMuPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e11fcc05-20c2-4e00-8c81-1efc1bc433fc"
      },
      "source": [
        "os.chdir('/content/drive/My Drive/AOI') #切換該目錄\r\n",
        "os.listdir() #確認目錄內容"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test_images.zip',\n",
              " 'classify',\n",
              " 'Model.h5',\n",
              " 'test_images',\n",
              " 'csv',\n",
              " 'QC_Sampling.ipynb',\n",
              " 'QC_Diff_of_Predictions.ipynb',\n",
              " 'TL_VGG16',\n",
              " 'Model.ipynb',\n",
              " 'QC_toCSV.ipynb',\n",
              " 'TL_InceptionV3',\n",
              " 'TL_ResNet50',\n",
              " 'VGG16.ipynb',\n",
              " 'VGG16-valAcc9683.h5',\n",
              " 'ResNet50.h5',\n",
              " 'image_compare.ipynb',\n",
              " 'Model_Predict.ipynb',\n",
              " 'InceptionV3.h5',\n",
              " 'InceptionV3.ipynb',\n",
              " 'ResNet50.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQW-JIE2Oq7G"
      },
      "source": [
        "# input 為 灰階 256 * 256 圖像\r\n",
        "# 灰階 為 1 通道\r\n",
        "input_shape = (256, 256, 3)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stwAy9N81k-G"
      },
      "source": [
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras.models import Model\n",
        "from tensorflow.python.keras.layers import Flatten, Dense, Dropout\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjcEIar51k-H"
      },
      "source": [
        "# 資料路徑\n",
        "DATASET_PATH  = 'classify'\n",
        "\n",
        "# 影像大小\n",
        "IMAGE_SIZE = (256,256)\n",
        "\n",
        "# 影像類別數\n",
        "NUM_CLASSES = 6\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# 凍結網路層數\n",
        "FREEZE_LAYERS = 2\n",
        "\n",
        "NUM_EPOCHS = 500\n",
        "\n",
        "# 模型輸出儲存的檔案\n",
        "WEIGHTS_FINAL = 'ResNet50.h5'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eB5qHcOn1k-H",
        "outputId": "88b6009d-bc72-4c55-eae5-fa48b6a2a28b"
      },
      "source": [
        "# 透過 data augmentation 產生訓練與驗證用的影像資料\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1/255.,\n",
        "    width_shift_range=1.0,\n",
        "    height_shift_range=1.0,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    validation_split = 0.2\n",
        ")\n",
        "train_batches = train_datagen.flow_from_directory(\n",
        "    DATASET_PATH,                                             \n",
        "    target_size=IMAGE_SIZE,\n",
        "    interpolation='bicubic',\n",
        "    class_mode='categorical',                                                  \n",
        "    batch_size=BATCH_SIZE,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "valid_datagen = ImageDataGenerator()\n",
        "valid_batches = train_datagen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    interpolation='bicubic',\n",
        "    class_mode='categorical',                                                  \n",
        "    batch_size=BATCH_SIZE,\n",
        "    subset='validation'\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4047 images belonging to 6 classes.\n",
            "Found 1009 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrpXFKms1k-I",
        "outputId": "e1b55659-81cd-46e9-b1fb-3b242747a98b"
      },
      "source": [
        "# 以訓練好的 ResNet50 為基礎來建立模型，\n",
        "# 捨棄 ResNet50 頂層的 fully connected layers\n",
        "net = ResNet50(include_top=False, weights='imagenet', input_tensor=None,\n",
        "               input_shape=(IMAGE_SIZE[0],IMAGE_SIZE[1],3))\n",
        "x = net.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "\n",
        "# 增加 DropOut layer\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# 增加 Dense layer，以 softmax 產生個類別的機率值\n",
        "output_layer = Dense(NUM_CLASSES, activation='softmax', name='softmax')(x)\n",
        "\n",
        "# 設定凍結與要進行訓練的網路層\n",
        "net_final = Model(inputs=net.input, outputs=output_layer)\n",
        "for layer in net_final.layers[:FREEZE_LAYERS]:\n",
        "    layer.trainable = False\n",
        "for layer in net_final.layers[FREEZE_LAYERS:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# 輸出整個網路結構\n",
        "net_final.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 0s 0us/step\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 131072)       0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          33554688    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Dense)                 (None, 6)            1542        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 57,143,942\n",
            "Trainable params: 57,090,822\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldoyWsN-15sF"
      },
      "source": [
        "# 使用 Adam optimizer，以較低的 learning rate 進行 fine-tuning\r\n",
        "net_final.compile(optimizer=Adam(lr=1e-5),\r\n",
        "                  loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7D4HvCu2PTM"
      },
      "source": [
        "from datetime import datetime\r\n",
        "\r\n",
        "model_dir = os.path.join(\r\n",
        "    'TL_ResNet50',\r\n",
        "    datetime.now().strftime('%y%m%d_%H%M')\r\n",
        ")\r\n",
        "os.makedirs(model_dir, exist_ok=True)\r\n",
        "\r\n",
        "dir_weights = os.path.join(model_dir, 'weights')\r\n",
        "os.makedirs(dir_weights, exist_ok=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCPvDvc92JvK"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\r\n",
        "\r\n",
        "# ModelCheckpoint\r\n",
        "cp_filepath = os.path.join(dir_weights, 'ep_{epoch:02d}_ls_{val_categorical_accuracy:.2f}.h5')\r\n",
        "cp = ModelCheckpoint(\r\n",
        "    cp_filepath,\r\n",
        "    monitor='val_categorical_accuracy',\r\n",
        "    verbose=1,\r\n",
        "    save_best_only=True,\r\n",
        "    save_weights_only=False,\r\n",
        "    mode='auto',\r\n",
        "    save_freq='epoch'\r\n",
        ")\r\n",
        "\r\n",
        "# CSVLogger\r\n",
        "csv_filepath = os.path.join(model_dir, 'loss.csv')\r\n",
        "csv = CSVLogger(csv_filepath, append=True)\r\n",
        "\r\n",
        "# EarlyStopping\r\n",
        "estop = EarlyStopping(\r\n",
        "    monitor='val_categorical_accuracy',\r\n",
        "    # min_delta=0.0001,\r\n",
        "    patience=32, \r\n",
        "    verbose=1,\r\n",
        "    mode='auto',\r\n",
        "    restore_best_weights=True\r\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tFCB7noszQR",
        "outputId": "2394a3a7-d9bd-462a-9869-362856e4cdeb"
      },
      "source": [
        "# 訓練模型\n",
        "history = net_final.fit_generator(\n",
        "  train_batches,\n",
        "  steps_per_epoch = train_batches.samples // BATCH_SIZE,\n",
        "  validation_data = valid_batches,\n",
        "  validation_steps = valid_batches.samples // BATCH_SIZE,\n",
        "  epochs = NUM_EPOCHS,\n",
        "  callbacks = [cp, csv, estop]\n",
        ")\n",
        "\n",
        "# 儲存訓練好的模型\n",
        "net_final.save(WEIGHTS_FINAL)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "252/252 [==============================] - 1578s 6s/step - loss: 1.3276 - categorical_accuracy: 0.6345 - val_loss: 50.5624 - val_categorical_accuracy: 0.1944\n",
            "\n",
            "Epoch 00001: val_categorical_accuracy improved from -inf to 0.19444, saving model to TL_ResNet50/210121_0005/weights/ep_01_ls_0.19.h5\n",
            "Epoch 2/500\n",
            "252/252 [==============================] - 97s 383ms/step - loss: 0.3285 - categorical_accuracy: 0.8891 - val_loss: 136.2991 - val_categorical_accuracy: 0.1944\n",
            "\n",
            "Epoch 00002: val_categorical_accuracy did not improve from 0.19444\n",
            "Epoch 3/500\n",
            "252/252 [==============================] - 95s 378ms/step - loss: 0.2161 - categorical_accuracy: 0.9270 - val_loss: 88.2825 - val_categorical_accuracy: 0.1687\n",
            "\n",
            "Epoch 00003: val_categorical_accuracy did not improve from 0.19444\n",
            "Epoch 4/500\n",
            "252/252 [==============================] - 96s 380ms/step - loss: 0.1554 - categorical_accuracy: 0.9476 - val_loss: 1.0995 - val_categorical_accuracy: 0.7966\n",
            "\n",
            "Epoch 00004: val_categorical_accuracy improved from 0.19444 to 0.79663, saving model to TL_ResNet50/210121_0005/weights/ep_04_ls_0.80.h5\n",
            "Epoch 5/500\n",
            "252/252 [==============================] - 98s 387ms/step - loss: 0.1368 - categorical_accuracy: 0.9521 - val_loss: 0.1560 - val_categorical_accuracy: 0.9504\n",
            "\n",
            "Epoch 00005: val_categorical_accuracy improved from 0.79663 to 0.95040, saving model to TL_ResNet50/210121_0005/weights/ep_05_ls_0.95.h5\n",
            "Epoch 6/500\n",
            "252/252 [==============================] - 97s 386ms/step - loss: 0.1062 - categorical_accuracy: 0.9653 - val_loss: 0.1228 - val_categorical_accuracy: 0.9692\n",
            "\n",
            "Epoch 00006: val_categorical_accuracy improved from 0.95040 to 0.96925, saving model to TL_ResNet50/210121_0005/weights/ep_06_ls_0.97.h5\n",
            "Epoch 7/500\n",
            "252/252 [==============================] - 97s 386ms/step - loss: 0.0829 - categorical_accuracy: 0.9702 - val_loss: 0.0784 - val_categorical_accuracy: 0.9802\n",
            "\n",
            "Epoch 00007: val_categorical_accuracy improved from 0.96925 to 0.98016, saving model to TL_ResNet50/210121_0005/weights/ep_07_ls_0.98.h5\n",
            "Epoch 8/500\n",
            "252/252 [==============================] - 98s 389ms/step - loss: 0.1059 - categorical_accuracy: 0.9647 - val_loss: 0.1695 - val_categorical_accuracy: 0.9514\n",
            "\n",
            "Epoch 00008: val_categorical_accuracy did not improve from 0.98016\n",
            "Epoch 9/500\n",
            "252/252 [==============================] - 97s 384ms/step - loss: 0.0721 - categorical_accuracy: 0.9796 - val_loss: 0.0887 - val_categorical_accuracy: 0.9792\n",
            "\n",
            "Epoch 00009: val_categorical_accuracy did not improve from 0.98016\n",
            "Epoch 10/500\n",
            "252/252 [==============================] - 96s 382ms/step - loss: 0.0602 - categorical_accuracy: 0.9817 - val_loss: 0.1176 - val_categorical_accuracy: 0.9841\n",
            "\n",
            "Epoch 00010: val_categorical_accuracy improved from 0.98016 to 0.98413, saving model to TL_ResNet50/210121_0005/weights/ep_10_ls_0.98.h5\n",
            "Epoch 11/500\n",
            "252/252 [==============================] - 98s 387ms/step - loss: 0.0738 - categorical_accuracy: 0.9785 - val_loss: 0.1355 - val_categorical_accuracy: 0.9792\n",
            "\n",
            "Epoch 00011: val_categorical_accuracy did not improve from 0.98413\n",
            "Epoch 12/500\n",
            "252/252 [==============================] - 97s 383ms/step - loss: 0.0535 - categorical_accuracy: 0.9835 - val_loss: 0.2637 - val_categorical_accuracy: 0.9464\n",
            "\n",
            "Epoch 00012: val_categorical_accuracy did not improve from 0.98413\n",
            "Epoch 13/500\n",
            "252/252 [==============================] - 97s 383ms/step - loss: 0.0463 - categorical_accuracy: 0.9837 - val_loss: 0.2910 - val_categorical_accuracy: 0.9236\n",
            "\n",
            "Epoch 00013: val_categorical_accuracy did not improve from 0.98413\n",
            "Epoch 14/500\n",
            "252/252 [==============================] - 97s 383ms/step - loss: 0.0473 - categorical_accuracy: 0.9852 - val_loss: 0.0839 - val_categorical_accuracy: 0.9851\n",
            "\n",
            "Epoch 00014: val_categorical_accuracy improved from 0.98413 to 0.98512, saving model to TL_ResNet50/210121_0005/weights/ep_14_ls_0.99.h5\n",
            "Epoch 15/500\n",
            "252/252 [==============================] - 97s 386ms/step - loss: 0.0330 - categorical_accuracy: 0.9870 - val_loss: 0.0890 - val_categorical_accuracy: 0.9812\n",
            "\n",
            "Epoch 00015: val_categorical_accuracy did not improve from 0.98512\n",
            "Epoch 16/500\n",
            "252/252 [==============================] - 96s 379ms/step - loss: 0.0277 - categorical_accuracy: 0.9918 - val_loss: 0.0798 - val_categorical_accuracy: 0.9851\n",
            "\n",
            "Epoch 00016: val_categorical_accuracy did not improve from 0.98512\n",
            "Epoch 17/500\n",
            "252/252 [==============================] - 96s 380ms/step - loss: 0.0409 - categorical_accuracy: 0.9885 - val_loss: 0.0877 - val_categorical_accuracy: 0.9851\n",
            "\n",
            "Epoch 00017: val_categorical_accuracy did not improve from 0.98512\n",
            "Epoch 18/500\n",
            "252/252 [==============================] - 96s 379ms/step - loss: 0.0327 - categorical_accuracy: 0.9859 - val_loss: 0.0867 - val_categorical_accuracy: 0.9921\n",
            "\n",
            "Epoch 00018: val_categorical_accuracy improved from 0.98512 to 0.99206, saving model to TL_ResNet50/210121_0005/weights/ep_18_ls_0.99.h5\n",
            "Epoch 19/500\n",
            "252/252 [==============================] - 97s 383ms/step - loss: 0.0354 - categorical_accuracy: 0.9875 - val_loss: 0.0960 - val_categorical_accuracy: 0.9871\n",
            "\n",
            "Epoch 00019: val_categorical_accuracy did not improve from 0.99206\n",
            "Epoch 20/500\n",
            "252/252 [==============================] - 96s 382ms/step - loss: 0.0248 - categorical_accuracy: 0.9918 - val_loss: 0.0979 - val_categorical_accuracy: 0.9901\n",
            "\n",
            "Epoch 00020: val_categorical_accuracy did not improve from 0.99206\n",
            "Epoch 21/500\n",
            "252/252 [==============================] - 96s 379ms/step - loss: 0.0162 - categorical_accuracy: 0.9942 - val_loss: 0.1581 - val_categorical_accuracy: 0.9712\n",
            "\n",
            "Epoch 00021: val_categorical_accuracy did not improve from 0.99206\n",
            "Epoch 22/500\n",
            "252/252 [==============================] - 96s 379ms/step - loss: 0.0363 - categorical_accuracy: 0.9911 - val_loss: 0.0833 - val_categorical_accuracy: 0.9871\n",
            "\n",
            "Epoch 00022: val_categorical_accuracy did not improve from 0.99206\n",
            "Epoch 23/500\n",
            "252/252 [==============================] - 96s 380ms/step - loss: 0.0245 - categorical_accuracy: 0.9910 - val_loss: 0.2026 - val_categorical_accuracy: 0.9405\n",
            "\n",
            "Epoch 00023: val_categorical_accuracy did not improve from 0.99206\n",
            "Epoch 24/500\n",
            "252/252 [==============================] - 96s 380ms/step - loss: 0.0189 - categorical_accuracy: 0.9922 - val_loss: 0.1479 - val_categorical_accuracy: 0.9772\n",
            "\n",
            "Epoch 00024: val_categorical_accuracy did not improve from 0.99206\n",
            "Epoch 25/500\n",
            "252/252 [==============================] - 96s 379ms/step - loss: 0.0342 - categorical_accuracy: 0.9920 - val_loss: 0.0963 - val_categorical_accuracy: 0.9891\n",
            "\n",
            "Epoch 00025: val_categorical_accuracy did not improve from 0.99206\n",
            "Epoch 26/500\n",
            "252/252 [==============================] - 96s 379ms/step - loss: 0.0307 - categorical_accuracy: 0.9942 - val_loss: 0.0877 - val_categorical_accuracy: 0.9901\n",
            "\n",
            "Epoch 00026: val_categorical_accuracy did not improve from 0.99206\n",
            "Epoch 27/500\n",
            "252/252 [==============================] - 96s 380ms/step - loss: 0.0171 - categorical_accuracy: 0.9949 - val_loss: 0.1021 - val_categorical_accuracy: 0.9940\n",
            "\n",
            "Epoch 00027: val_categorical_accuracy improved from 0.99206 to 0.99405, saving model to TL_ResNet50/210121_0005/weights/ep_27_ls_0.99.h5\n",
            "Epoch 28/500\n",
            "252/252 [==============================] - 96s 382ms/step - loss: 0.0155 - categorical_accuracy: 0.9932 - val_loss: 0.0826 - val_categorical_accuracy: 0.9901\n",
            "\n",
            "Epoch 00028: val_categorical_accuracy did not improve from 0.99405\n",
            "Epoch 29/500\n",
            "252/252 [==============================] - 95s 378ms/step - loss: 0.0178 - categorical_accuracy: 0.9945 - val_loss: 0.1753 - val_categorical_accuracy: 0.9692\n",
            "\n",
            "Epoch 00029: val_categorical_accuracy did not improve from 0.99405\n",
            "Epoch 30/500\n",
            "252/252 [==============================] - 96s 380ms/step - loss: 0.0699 - categorical_accuracy: 0.9929 - val_loss: 0.0793 - val_categorical_accuracy: 0.9911\n",
            "\n",
            "Epoch 00030: val_categorical_accuracy did not improve from 0.99405\n",
            "Epoch 31/500\n",
            "252/252 [==============================] - 96s 381ms/step - loss: 0.0230 - categorical_accuracy: 0.9927 - val_loss: 0.0895 - val_categorical_accuracy: 0.9931\n",
            "\n",
            "Epoch 00031: val_categorical_accuracy did not improve from 0.99405\n",
            "Epoch 32/500\n",
            "252/252 [==============================] - 95s 376ms/step - loss: 0.0132 - categorical_accuracy: 0.9964 - val_loss: 0.0918 - val_categorical_accuracy: 0.9911\n",
            "\n",
            "Epoch 00032: val_categorical_accuracy did not improve from 0.99405\n",
            "Epoch 33/500\n",
            "252/252 [==============================] - 95s 378ms/step - loss: 0.0109 - categorical_accuracy: 0.9967 - val_loss: 0.0995 - val_categorical_accuracy: 0.9881\n",
            "\n",
            "Epoch 00033: val_categorical_accuracy did not improve from 0.99405\n",
            "Epoch 34/500\n",
            "252/252 [==============================] - 95s 377ms/step - loss: 0.0156 - categorical_accuracy: 0.9948 - val_loss: 0.1103 - val_categorical_accuracy: 0.9851\n",
            "\n",
            "Epoch 00034: val_categorical_accuracy did not improve from 0.99405\n",
            "Epoch 35/500\n",
            "252/252 [==============================] - 95s 375ms/step - loss: 0.0143 - categorical_accuracy: 0.9968 - val_loss: 0.1259 - val_categorical_accuracy: 0.9921\n",
            "\n",
            "Epoch 00035: val_categorical_accuracy did not improve from 0.99405\n",
            "Epoch 36/500\n",
            "252/252 [==============================] - 94s 374ms/step - loss: 0.0116 - categorical_accuracy: 0.9960 - val_loss: 0.0958 - val_categorical_accuracy: 0.9901\n",
            "\n",
            "Epoch 00036: val_categorical_accuracy did not improve from 0.99405\n",
            "Epoch 37/500\n",
            "252/252 [==============================] - 94s 373ms/step - loss: 0.0288 - categorical_accuracy: 0.9939 - val_loss: 0.0963 - val_categorical_accuracy: 0.9921\n",
            "\n",
            "Epoch 00037: val_categorical_accuracy did not improve from 0.99405\n",
            "Epoch 38/500\n",
            "252/252 [==============================] - 94s 371ms/step - loss: 0.0092 - categorical_accuracy: 0.9963 - val_loss: 0.0947 - val_categorical_accuracy: 0.9911\n",
            "\n",
            "Epoch 00038: val_categorical_accuracy did not improve from 0.99405\n",
            "Epoch 39/500\n",
            "252/252 [==============================] - 94s 371ms/step - loss: 0.0116 - categorical_accuracy: 0.9969 - val_loss: 0.0967 - val_categorical_accuracy: 0.9901\n",
            "\n",
            "Epoch 00039: val_categorical_accuracy did not improve from 0.99405\n",
            "Epoch 40/500\n",
            "252/252 [==============================] - 96s 379ms/step - loss: 0.0109 - categorical_accuracy: 0.9953 - val_loss: 0.1323 - val_categorical_accuracy: 0.9940\n",
            "\n",
            "Epoch 00040: val_categorical_accuracy did not improve from 0.99405\n",
            "Epoch 41/500\n",
            "252/252 [==============================] - 94s 374ms/step - loss: 0.0079 - categorical_accuracy: 0.9977 - val_loss: 0.2420 - val_categorical_accuracy: 0.9722\n",
            "\n",
            "Epoch 00041: val_categorical_accuracy did not improve from 0.99405\n",
            "Epoch 42/500\n",
            "252/252 [==============================] - 95s 378ms/step - loss: 0.0210 - categorical_accuracy: 0.9931 - val_loss: 0.1437 - val_categorical_accuracy: 0.9881\n",
            "\n",
            "Epoch 00042: val_categorical_accuracy did not improve from 0.99405\n",
            "Epoch 43/500\n",
            "252/252 [==============================] - 95s 375ms/step - loss: 0.0153 - categorical_accuracy: 0.9954 - val_loss: 0.1517 - val_categorical_accuracy: 0.9861\n",
            "\n",
            "Epoch 00043: val_categorical_accuracy did not improve from 0.99405\n",
            "Epoch 44/500\n",
            "252/252 [==============================] - 94s 372ms/step - loss: 0.0105 - categorical_accuracy: 0.9955 - val_loss: 0.1383 - val_categorical_accuracy: 0.9911\n",
            "\n",
            "Epoch 00044: val_categorical_accuracy did not improve from 0.99405\n",
            "Epoch 45/500\n",
            "252/252 [==============================] - 94s 372ms/step - loss: 0.0048 - categorical_accuracy: 0.9984 - val_loss: 0.1253 - val_categorical_accuracy: 0.9851\n",
            "\n",
            "Epoch 00045: val_categorical_accuracy did not improve from 0.99405\n",
            "Epoch 46/500\n",
            "252/252 [==============================] - 94s 372ms/step - loss: 0.0093 - categorical_accuracy: 0.9969 - val_loss: 0.1329 - val_categorical_accuracy: 0.9911\n",
            "\n",
            "Epoch 00046: val_categorical_accuracy did not improve from 0.99405\n",
            "Epoch 47/500\n",
            "252/252 [==============================] - 94s 371ms/step - loss: 0.0220 - categorical_accuracy: 0.9976 - val_loss: 0.0971 - val_categorical_accuracy: 0.9921\n",
            "\n",
            "Epoch 00047: val_categorical_accuracy did not improve from 0.99405\n",
            "Epoch 48/500\n",
            "252/252 [==============================] - 94s 371ms/step - loss: 0.0075 - categorical_accuracy: 0.9973 - val_loss: 0.1129 - val_categorical_accuracy: 0.9950\n",
            "\n",
            "Epoch 00048: val_categorical_accuracy improved from 0.99405 to 0.99504, saving model to TL_ResNet50/210121_0005/weights/ep_48_ls_1.00.h5\n",
            "Epoch 49/500\n",
            "252/252 [==============================] - 95s 376ms/step - loss: 0.0051 - categorical_accuracy: 0.9984 - val_loss: 0.0906 - val_categorical_accuracy: 0.9921\n",
            "\n",
            "Epoch 00049: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 50/500\n",
            "252/252 [==============================] - 94s 373ms/step - loss: 0.0036 - categorical_accuracy: 0.9990 - val_loss: 0.0852 - val_categorical_accuracy: 0.9940\n",
            "\n",
            "Epoch 00050: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 51/500\n",
            "252/252 [==============================] - 94s 372ms/step - loss: 0.0028 - categorical_accuracy: 0.9988 - val_loss: 0.0665 - val_categorical_accuracy: 0.9931\n",
            "\n",
            "Epoch 00051: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 52/500\n",
            "252/252 [==============================] - 94s 371ms/step - loss: 0.0172 - categorical_accuracy: 0.9968 - val_loss: 0.1299 - val_categorical_accuracy: 0.9911\n",
            "\n",
            "Epoch 00052: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 53/500\n",
            "252/252 [==============================] - 94s 373ms/step - loss: 0.0096 - categorical_accuracy: 0.9979 - val_loss: 0.1182 - val_categorical_accuracy: 0.9911\n",
            "\n",
            "Epoch 00053: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 54/500\n",
            "252/252 [==============================] - 94s 372ms/step - loss: 0.0108 - categorical_accuracy: 0.9964 - val_loss: 0.0648 - val_categorical_accuracy: 0.9931\n",
            "\n",
            "Epoch 00054: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 55/500\n",
            "252/252 [==============================] - 94s 371ms/step - loss: 0.0054 - categorical_accuracy: 0.9980 - val_loss: 0.1152 - val_categorical_accuracy: 0.9921\n",
            "\n",
            "Epoch 00055: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 56/500\n",
            "252/252 [==============================] - 94s 374ms/step - loss: 0.0023 - categorical_accuracy: 0.9992 - val_loss: 0.1171 - val_categorical_accuracy: 0.9921\n",
            "\n",
            "Epoch 00056: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 57/500\n",
            "252/252 [==============================] - 94s 372ms/step - loss: 0.0026 - categorical_accuracy: 0.9995 - val_loss: 0.0976 - val_categorical_accuracy: 0.9950\n",
            "\n",
            "Epoch 00057: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 58/500\n",
            "252/252 [==============================] - 94s 371ms/step - loss: 0.0184 - categorical_accuracy: 0.9963 - val_loss: 0.2280 - val_categorical_accuracy: 0.9831\n",
            "\n",
            "Epoch 00058: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 59/500\n",
            "252/252 [==============================] - 94s 373ms/step - loss: 0.0129 - categorical_accuracy: 0.9952 - val_loss: 0.0988 - val_categorical_accuracy: 0.9931\n",
            "\n",
            "Epoch 00059: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 60/500\n",
            "252/252 [==============================] - 94s 373ms/step - loss: 0.0140 - categorical_accuracy: 0.9961 - val_loss: 0.1290 - val_categorical_accuracy: 0.9921\n",
            "\n",
            "Epoch 00060: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 61/500\n",
            "252/252 [==============================] - 94s 371ms/step - loss: 0.0089 - categorical_accuracy: 0.9978 - val_loss: 0.1109 - val_categorical_accuracy: 0.9871\n",
            "\n",
            "Epoch 00061: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 62/500\n",
            "252/252 [==============================] - 93s 370ms/step - loss: 0.0053 - categorical_accuracy: 0.9977 - val_loss: 0.1029 - val_categorical_accuracy: 0.9921\n",
            "\n",
            "Epoch 00062: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 63/500\n",
            "252/252 [==============================] - 94s 371ms/step - loss: 0.0096 - categorical_accuracy: 0.9978 - val_loss: 0.0970 - val_categorical_accuracy: 0.9911\n",
            "\n",
            "Epoch 00063: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 64/500\n",
            "252/252 [==============================] - 93s 370ms/step - loss: 0.0097 - categorical_accuracy: 0.9964 - val_loss: 0.1028 - val_categorical_accuracy: 0.9921\n",
            "\n",
            "Epoch 00064: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 65/500\n",
            "252/252 [==============================] - 93s 370ms/step - loss: 0.0081 - categorical_accuracy: 0.9982 - val_loss: 0.1138 - val_categorical_accuracy: 0.9931\n",
            "\n",
            "Epoch 00065: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 66/500\n",
            "252/252 [==============================] - 94s 371ms/step - loss: 0.0083 - categorical_accuracy: 0.9982 - val_loss: 0.4912 - val_categorical_accuracy: 0.9048\n",
            "\n",
            "Epoch 00066: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 67/500\n",
            "252/252 [==============================] - 93s 370ms/step - loss: 0.0341 - categorical_accuracy: 0.9971 - val_loss: 0.1357 - val_categorical_accuracy: 0.9950\n",
            "\n",
            "Epoch 00067: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 68/500\n",
            "252/252 [==============================] - 94s 371ms/step - loss: 0.0054 - categorical_accuracy: 0.9983 - val_loss: 0.1490 - val_categorical_accuracy: 0.9911\n",
            "\n",
            "Epoch 00068: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 69/500\n",
            "252/252 [==============================] - 94s 371ms/step - loss: 0.0031 - categorical_accuracy: 0.9987 - val_loss: 0.1172 - val_categorical_accuracy: 0.9921\n",
            "\n",
            "Epoch 00069: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 70/500\n",
            "252/252 [==============================] - 95s 375ms/step - loss: 0.0033 - categorical_accuracy: 0.9986 - val_loss: 0.1573 - val_categorical_accuracy: 0.9861\n",
            "\n",
            "Epoch 00070: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 71/500\n",
            "252/252 [==============================] - 94s 373ms/step - loss: 0.0031 - categorical_accuracy: 0.9994 - val_loss: 0.1099 - val_categorical_accuracy: 0.9940\n",
            "\n",
            "Epoch 00071: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 72/500\n",
            "252/252 [==============================] - 94s 373ms/step - loss: 0.0082 - categorical_accuracy: 0.9987 - val_loss: 0.1054 - val_categorical_accuracy: 0.9931\n",
            "\n",
            "Epoch 00072: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 73/500\n",
            "252/252 [==============================] - 94s 373ms/step - loss: 0.0104 - categorical_accuracy: 0.9975 - val_loss: 0.1579 - val_categorical_accuracy: 0.9931\n",
            "\n",
            "Epoch 00073: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 74/500\n",
            "252/252 [==============================] - 94s 373ms/step - loss: 0.0034 - categorical_accuracy: 0.9989 - val_loss: 0.1330 - val_categorical_accuracy: 0.9931\n",
            "\n",
            "Epoch 00074: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 75/500\n",
            "252/252 [==============================] - 94s 371ms/step - loss: 0.0449 - categorical_accuracy: 0.9975 - val_loss: 0.1400 - val_categorical_accuracy: 0.9911\n",
            "\n",
            "Epoch 00075: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 76/500\n",
            "252/252 [==============================] - 94s 372ms/step - loss: 0.0034 - categorical_accuracy: 0.9993 - val_loss: 0.1134 - val_categorical_accuracy: 0.9921\n",
            "\n",
            "Epoch 00076: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 77/500\n",
            "252/252 [==============================] - 94s 371ms/step - loss: 0.0141 - categorical_accuracy: 0.9981 - val_loss: 0.1425 - val_categorical_accuracy: 0.9911\n",
            "\n",
            "Epoch 00077: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 78/500\n",
            "252/252 [==============================] - 94s 371ms/step - loss: 0.0031 - categorical_accuracy: 0.9990 - val_loss: 0.1350 - val_categorical_accuracy: 0.9931\n",
            "\n",
            "Epoch 00078: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 79/500\n",
            "252/252 [==============================] - 94s 371ms/step - loss: 0.0061 - categorical_accuracy: 0.9976 - val_loss: 0.1511 - val_categorical_accuracy: 0.9921\n",
            "\n",
            "Epoch 00079: val_categorical_accuracy did not improve from 0.99504\n",
            "Epoch 80/500\n",
            "252/252 [==============================] - 94s 371ms/step - loss: 0.0031 - categorical_accuracy: 0.9992 - val_loss: 0.1354 - val_categorical_accuracy: 0.9940\n",
            "\n",
            "Epoch 00080: val_categorical_accuracy did not improve from 0.99504\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00080: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNrptga4fZxr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb7496df-3c52-4f9e-fd04-92c58c3802b8"
      },
      "source": [
        "loss, accuracy = net_final.evaluate_generator(valid_batches)\r\n",
        "print(f'loss = {loss:.2f}')\r\n",
        "print(f'accuracy = {accuracy:.2f}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss = 0.09\n",
            "accuracy = 0.99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "RWrz_5Fi4qkt",
        "outputId": "2f97616a-4646-4fa2-a1f6-39117203ddbe"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "loss = history.history['loss']\r\n",
        "acc = history.history['categorical_accuracy']\r\n",
        "epochs = range(1, len(loss)+1)\r\n",
        "val_loss = history.history['val_loss']\r\n",
        "val_acc = history.history['val_categorical_accuracy']\r\n",
        "\r\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2)\r\n",
        "ax[0].plot(epochs, loss, 'b', label='loss')\r\n",
        "ax[0].plot(epochs, val_loss, 'r', label='validation loss')\r\n",
        "ax[0].legend()\r\n",
        "ax[1].plot(epochs, acc, 'b', label='accuracy')\r\n",
        "ax[1].plot(epochs, val_acc, 'r', label='validation accuracy')\r\n",
        "ax[1].legend()\r\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKX8_PiF4sNG",
        "outputId": "ec0ebd0a-df3a-4784-dca4-583094b08112"
      },
      "source": [
        "valid_datagen = ImageDataGenerator(\r\n",
        "    rescale=1./255\r\n",
        "    # preprocessing_function=preprocess_input\r\n",
        ")\r\n",
        "\r\n",
        "evaluate_itr = valid_datagen.flow_from_directory(\r\n",
        "    './classify',\r\n",
        "    target_size=(256, 256),\r\n",
        "    batch_size=64,\r\n",
        "    class_mode='categorical',\r\n",
        "    shuffle=False\r\n",
        ")\r\n",
        "\r\n",
        "loss, accuracy = net_final.evaluate_generator(evaluate_itr)\r\n",
        "print(f'loss = {loss:.2f}')\r\n",
        "print(f'accuracy = {accuracy:.2f}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5056 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss = 0.02\n",
            "accuracy = 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrxLhiK94t3H",
        "outputId": "a3b4eb89-704b-4565-fe3f-39b6de1b6071"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "# labels\r\n",
        "labels = evaluate_itr.class_indices\r\n",
        "\r\n",
        "# then use predict_geneorator to predict the result base on model\r\n",
        "evaluate_itr.reset()\r\n",
        "pred = net_final.predict_generator(evaluate_itr, verbose=1)\r\n",
        "\r\n",
        "# prediction from model\r\n",
        "predicted_class_indices = np.argmax(pred, axis=1)\r\n",
        "# real results in training set\r\n",
        "true_label= evaluate_itr.classes"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 22s 270ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "62IV06z64uQJ",
        "outputId": "5591cbe9-556e-4063-cdaa-0bdef3a59052"
      },
      "source": [
        "#使用pd.crosstab来简单画出混淆矩阵\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "table = pd.crosstab(predicted_class_indices, true_label,colnames=['predict'], rownames=['label'])\r\n",
        "table"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>predict</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1347</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>982</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>756</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>476</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1288</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "predict     0    1    2    3    4     5\n",
              "label                                  \n",
              "0        1347    0    0    0    0     0\n",
              "1           0  982    0    0    0     0\n",
              "2           1    0  200    0    0     0\n",
              "3           0    1    0  756    4     0\n",
              "4           0    0    0    0  476     0\n",
              "5           0    1    0    0    0  1288"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}