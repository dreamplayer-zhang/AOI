{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import imagehash\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "class DuplicateRemover:\n",
    "    def __init__(self,dirname,hash_size = 8):\n",
    "        self.dirname = dirname\n",
    "        self.hash_size = hash_size\n",
    "        \n",
    "    def find_duplicates(self):\n",
    "        \"\"\"\n",
    "        Find and Delete Duplicates\n",
    "        \"\"\"\n",
    "        \n",
    "        fnames = os.listdir(self.dirname)\n",
    "        hashes = {}\n",
    "        duplicates = []\n",
    "        print(\"Finding Duplicates Now!\\n\")\n",
    "        for image in fnames:\n",
    "            if image[-4:] != '.jpg':\n",
    "                continue\n",
    "            with Image.open(os.path.join(self.dirname,image)) as img:\n",
    "                temp_hash = imagehash.average_hash(img, self.hash_size)\n",
    "                if temp_hash in hashes:\n",
    "                    print(\"Duplicate {} \\nfound for Image {}!\\n\".format(image,hashes[temp_hash]))\n",
    "                    duplicates.append(image)\n",
    "                else:\n",
    "                    hashes[temp_hash] = image\n",
    "                   \n",
    "        # if len(duplicates) != 0:\n",
    "        #     a = input(\"Do you want to delete these {} Images? Press Y or N:  \".format(len(duplicates)))\n",
    "        #     space_saved = 0\n",
    "        #     if(a.strip().lower() == \"y\"):\n",
    "        #         for duplicate in duplicates:\n",
    "        #             space_saved += os.path.getsize(os.path.join(self.dirname,duplicate))\n",
    "                    \n",
    "        #             os.remove(os.path.join(self.dirname,duplicate))\n",
    "        #             print(\"{} Deleted Succesfully!\".format(duplicate))\n",
    "    \n",
    "        #         print(\"\\n\\nYou saved {} mb of Space!\".format(round(space_saved/1000000),2))\n",
    "        #     else:\n",
    "        #         print(\"Thank you for Using Duplicate Remover\")\n",
    "        # else:\n",
    "        #     print(\"No Duplicates Found :(\")\n",
    "        print(len(duplicates))\n",
    "            \n",
    "        \n",
    "            \n",
    "            \n",
    "    def find_similar(self, location, similarity=80):\n",
    "        # similars\n",
    "        res = []\n",
    "\n",
    "        fnames = os.listdir(self.dirname)\n",
    "        threshold = 1 - similarity/100\n",
    "        diff_limit = int(threshold*(self.hash_size**2))\n",
    "        \n",
    "        with Image.open(os.path.join(self.dirname, location)) as img:\n",
    "            hash1 = imagehash.average_hash(img, self.hash_size).hash\n",
    "        \n",
    "        print(\"Finding Similar Images to {} Now!\".format(location))\n",
    "        for image in fnames:\n",
    "            if image[-4:] != '.jpg' or image == location:\n",
    "                continue\n",
    "            with Image.open(os.path.join(self.dirname,image)) as img:\n",
    "                hash2 = imagehash.average_hash(img, self.hash_size).hash\n",
    "                \n",
    "                if np.count_nonzero(hash1 != hash2) <= diff_limit:\n",
    "                    print(\"{} image found {}% similar to {}\".format(image,similarity,location))\n",
    "                    res.append(image)\n",
    "        return res\n",
    "\n",
    "    def find_similar_all(self, tot_size, similarity=80):\n",
    "        similars = []\n",
    "\n",
    "        # Find Similar Images and iter all photos\n",
    "        for i in tqdm(range(0, tot_size)):\n",
    "\n",
    "            index = str(i)\n",
    "            index = '0' * (5 - len(index)) + index\n",
    "            target = f'train_{index}.jpg'\n",
    "\n",
    "            if target in similars:\n",
    "                continue\n",
    "\n",
    "            res = dr.find_similar(target, 95)\n",
    "            similars.extend(res)\n",
    "        return similars\n",
    "\n",
    "    def find_Unsimilar(self, location, Unsimilarity=80):\n",
    "        # similars\n",
    "        res = []\n",
    "\n",
    "        fnames = os.listdir(self.dirname)\n",
    "        threshold = Unsimilarity/100\n",
    "        diff_limit = int(threshold*(self.hash_size**2))\n",
    "        \n",
    "        with Image.open(os.path.join(self.dirname, location)) as img:\n",
    "            hash1 = imagehash.average_hash(img, self.hash_size).hash\n",
    "        \n",
    "        print(\"Finding Un-Similar Images to {} Now!\".format(location))\n",
    "        for image in fnames:\n",
    "            if image[-4:] != '.jpg' or image == location:\n",
    "                continue\n",
    "            with Image.open(os.path.join(self.dirname,image)) as img:\n",
    "                hash2 = imagehash.average_hash(img, self.hash_size).hash\n",
    "                \n",
    "                if np.count_nonzero(hash1 != hash2) >= diff_limit:\n",
    "                    print(\"{} image found {}% Un-similar to {}\".format(image,Unsimilarity,location))\n",
    "                    res.append(image)\n",
    "        return res\n"
   ]
  },
  {
   "source": [
    "# Duplicates Image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove Duplicates\n",
    "# dirname = './classify'\n",
    "\n",
    "# dr = DuplicateRemover(dirname)\n",
    "# dr.find_duplicates()"
   ]
  },
  {
   "source": [
    "# Similar Image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finding Un-Similar Images to train_00001.jpg Now!\n",
      "train_00021.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00035.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00047.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00056.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00066.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00072.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00096.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00112.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00122.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00148.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00165.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00176.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00203.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00209.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00216.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00269.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00275.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00278.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00284.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00301.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00308.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00326.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00451.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00486.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00575.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00579.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00596.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00636.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00718.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_00960.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_01024.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_01074.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_01087.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_01104.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_01157.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_01297.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_01339.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_01341.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_01349.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_01431.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_01445.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_01497.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_01498.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_01594.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_01601.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_01627.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_01695.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_01778.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_01791.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_01886.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_01890.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_01955.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_02021.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_02097.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_02139.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_02183.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_02217.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_02255.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_02276.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_02282.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_02321.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_02338.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_02346.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_02355.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_02356.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_02365.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_02389.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_02450.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_02479.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_02651.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_03815.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_03855.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_03969.jpg image found 80% Un-similar to train_00001.jpg\n",
      "train_04610.jpg image found 80% Un-similar to train_00001.jpg\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['train_00021.jpg',\n",
       " 'train_00035.jpg',\n",
       " 'train_00047.jpg',\n",
       " 'train_00056.jpg',\n",
       " 'train_00066.jpg',\n",
       " 'train_00072.jpg',\n",
       " 'train_00096.jpg',\n",
       " 'train_00112.jpg',\n",
       " 'train_00122.jpg',\n",
       " 'train_00148.jpg',\n",
       " 'train_00165.jpg',\n",
       " 'train_00176.jpg',\n",
       " 'train_00203.jpg',\n",
       " 'train_00209.jpg',\n",
       " 'train_00216.jpg',\n",
       " 'train_00269.jpg',\n",
       " 'train_00275.jpg',\n",
       " 'train_00278.jpg',\n",
       " 'train_00284.jpg',\n",
       " 'train_00301.jpg',\n",
       " 'train_00308.jpg',\n",
       " 'train_00326.jpg',\n",
       " 'train_00451.jpg',\n",
       " 'train_00486.jpg',\n",
       " 'train_00575.jpg',\n",
       " 'train_00579.jpg',\n",
       " 'train_00596.jpg',\n",
       " 'train_00636.jpg',\n",
       " 'train_00718.jpg',\n",
       " 'train_00960.jpg',\n",
       " 'train_01024.jpg',\n",
       " 'train_01074.jpg',\n",
       " 'train_01087.jpg',\n",
       " 'train_01104.jpg',\n",
       " 'train_01157.jpg',\n",
       " 'train_01297.jpg',\n",
       " 'train_01339.jpg',\n",
       " 'train_01341.jpg',\n",
       " 'train_01349.jpg',\n",
       " 'train_01431.jpg',\n",
       " 'train_01445.jpg',\n",
       " 'train_01497.jpg',\n",
       " 'train_01498.jpg',\n",
       " 'train_01594.jpg',\n",
       " 'train_01601.jpg',\n",
       " 'train_01627.jpg',\n",
       " 'train_01695.jpg',\n",
       " 'train_01778.jpg',\n",
       " 'train_01791.jpg',\n",
       " 'train_01886.jpg',\n",
       " 'train_01890.jpg',\n",
       " 'train_01955.jpg',\n",
       " 'train_02021.jpg',\n",
       " 'train_02097.jpg',\n",
       " 'train_02139.jpg',\n",
       " 'train_02183.jpg',\n",
       " 'train_02217.jpg',\n",
       " 'train_02255.jpg',\n",
       " 'train_02276.jpg',\n",
       " 'train_02282.jpg',\n",
       " 'train_02321.jpg',\n",
       " 'train_02338.jpg',\n",
       " 'train_02346.jpg',\n",
       " 'train_02355.jpg',\n",
       " 'train_02356.jpg',\n",
       " 'train_02365.jpg',\n",
       " 'train_02389.jpg',\n",
       " 'train_02450.jpg',\n",
       " 'train_02479.jpg',\n",
       " 'train_02651.jpg',\n",
       " 'train_03815.jpg',\n",
       " 'train_03855.jpg',\n",
       " 'train_03969.jpg',\n",
       " 'train_04610.jpg']"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Remove Non-Similarity\n",
    "dirname = './classify'\n",
    "\n",
    "dr = DuplicateRemover(dirname + f'/class_{1}')\n",
    "dr.find_Unsimilar('train_00001.jpg', 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}