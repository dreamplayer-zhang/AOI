{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.9 64-bit ('python37': conda)",
      "metadata": {
        "interpreter": {
          "hash": "56918090559b2dfb924586d334310b74e75434cb73f2473ccf8876bfcc1690fc"
        }
      }
    },
    "colab": {
      "name": "VGG16.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMaLFwh4Rzrb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "834e565b-2d69-4fba-97e1-057433e6ba1f"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jan 19 08:00:38 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P8    12W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkDzayYbO32E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cec4e579-d07e-49bb-9d31-9c990c32fd70"
      },
      "source": [
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDYKQwwMRgO5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c43aab96-6a41-4ff3-e1d4-f935d4ba2b73"
      },
      "source": [
        "os.chdir('/content/drive/My Drive/AOI') #切換該目錄\r\n",
        "os.listdir() #確認目錄內容"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test_images.zip',\n",
              " 'classify',\n",
              " 'Model.h5',\n",
              " 'test_images',\n",
              " 'csv',\n",
              " 'Model_Predict.ipynb',\n",
              " 'QC_Sampling.ipynb',\n",
              " 'QC_Diff_of_Predictions.ipynb',\n",
              " 'TL_VGG16',\n",
              " 'Model.ipynb',\n",
              " 'VGG16-valAcc9594.h5',\n",
              " 'VGG16-valAcc9683.h5',\n",
              " 'QC_toCSV.ipynb',\n",
              " 'TL_InceptionV3',\n",
              " 'VGG16-valAcc9286.h5',\n",
              " 'InceptionV3.h5',\n",
              " 'image_compare.ipynb',\n",
              " 'VGG16.ipynb',\n",
              " 'InceptionV3.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej_slIVpO32I"
      },
      "source": [
        "# input 為 灰階 256 * 256 圖像\n",
        "# 灰階 為 1 通道\n",
        "input_shape = (256, 256, 3)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e85Flb0xO32J"
      },
      "source": [
        "# Model building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ja7anJSO32J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ddf9300-f25f-4a7c-96d0-5dc3ba95ccd0"
      },
      "source": [
        "from tensorflow.python.keras.applications.vgg16 import VGG16\n",
        "\n",
        "# transfer trainging\n",
        "# need not to include the output layer, we will redefine it later\n",
        "vgg16 = VGG16(include_top=False, input_shape=input_shape)\n",
        "vgg16.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpzHPBFwO32K"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "\n",
        "def build_model(vgg16):\n",
        "    model = Sequential(vgg16.layers)\n",
        "\n",
        "    for layer in model.layers[:15]:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "    # redefine the output layer to 6 class(AOI )\n",
        "    model.add(Dense(6, activation='sigmoid'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I3Aw1rUO32L"
      },
      "source": [
        "model = build_model(vgg16)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDNkK2UHO32L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d51f4f77-9e1d-4315-9d5a-4115b786a667"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "model.compile(\n",
        "    loss = 'categorical_crossentropy',\n",
        "    # optimizer=SGD(lr=1e-4, momentum=0.9),\n",
        "    optimizer=Adam(lr=1e-4),\n",
        "    metrics=['categorical_accuracy']\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               8388864   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 1542      \n",
            "=================================================================\n",
            "Total params: 23,105,094\n",
            "Trainable params: 13,110,022\n",
            "Non-trainable params: 9,995,072\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcM7N7VoO32L"
      },
      "source": [
        "# pre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwFtvl9rO32M"
      },
      "source": [
        "# 將輸入圖片擴張\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1/255.,\n",
        "    width_shift_range=1.0,\n",
        "    height_shift_range=1.0,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    preprocessing_function=preprocess_input,\n",
        "    validation_split = 0.2\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsoDEQtZO32M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0711d1a-d15f-4010-9fea-7fdcab973892"
      },
      "source": [
        "# 產生迭代器\n",
        "img_itr_train = train_datagen.flow_from_directory(\n",
        "    './classify',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "img_itr_valid = train_datagen.flow_from_directory(\n",
        "    './classify',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4047 images belonging to 6 classes.\n",
            "Found 1009 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75A5GtDa3IuY"
      },
      "source": [
        "# Callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oio7Vb-j3JA6"
      },
      "source": [
        "from datetime import datetime\r\n",
        "\r\n",
        "model_dir = os.path.join(\r\n",
        "    'TL_VGG16',\r\n",
        "    datetime.now().strftime('%y%m%d_%H%M')\r\n",
        ")\r\n",
        "os.makedirs(model_dir, exist_ok=True)\r\n",
        "\r\n",
        "dir_weights = os.path.join(model_dir, 'weights')\r\n",
        "os.makedirs(dir_weights, exist_ok=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4PbZQb25iVo"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\r\n",
        "\r\n",
        "# ModelCheckpoint\r\n",
        "cp_filepath = os.path.join(dir_weights, 'ep_{epoch:02d}_ls_{val_categorical_accuracy:.2f}.h5')\r\n",
        "cp = ModelCheckpoint(\r\n",
        "    cp_filepath,\r\n",
        "    monitor='val_categorical_accuracy',\r\n",
        "    verbose=1,\r\n",
        "    save_best_only=True,\r\n",
        "    save_weights_only=False,\r\n",
        "    mode='auto',\r\n",
        "    save_freq='epoch'\r\n",
        ")\r\n",
        "\r\n",
        "# CSVLogger\r\n",
        "csv_filepath = os.path.join(model_dir, 'loss.csv')\r\n",
        "csv = CSVLogger(csv_filepath, append=True)\r\n",
        "\r\n",
        "# EarlyStopping\r\n",
        "estop = EarlyStopping(\r\n",
        "    monitor='val_categorical_accuracy',\r\n",
        "    # min_delta=0.0001,\r\n",
        "    patience=32, \r\n",
        "    verbose=1,\r\n",
        "    mode='auto'\r\n",
        "    # restore_best_weights=False\r\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BJQlYAoO32N"
      },
      "source": [
        "# Trainging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwKXCJTAO32P"
      },
      "source": [
        "import math\n",
        "\n",
        "# 計算幾個批次為一次學習\n",
        "batch_size = 64\n",
        "steps_per_epoch = math.ceil(\n",
        "    img_itr_train.samples/batch_size\n",
        ")\n",
        "validation_steps = math.ceil(\n",
        "    img_itr_valid.samples/batch_size\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg5465siO32P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92969227-2385-4d50-ebf6-3a7dfe1b848a"
      },
      "source": [
        "history = model.fit_generator(\n",
        "    img_itr_train,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=500,\n",
        "    validation_data=img_itr_valid,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=[cp, csv, estop]\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "64/64 [==============================] - 87s 1s/step - loss: 0.9881 - categorical_accuracy: 0.6223 - val_loss: 0.6482 - val_categorical_accuracy: 0.7304\n",
            "\n",
            "Epoch 00001: val_categorical_accuracy improved from -inf to 0.73043, saving model to TL_VGG16/210119_0800/weights/ep_01_ls_0.73.h5\n",
            "Epoch 2/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.3799 - categorical_accuracy: 0.8609 - val_loss: 0.4631 - val_categorical_accuracy: 0.8285\n",
            "\n",
            "Epoch 00002: val_categorical_accuracy improved from 0.73043 to 0.82854, saving model to TL_VGG16/210119_0800/weights/ep_02_ls_0.83.h5\n",
            "Epoch 3/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.2976 - categorical_accuracy: 0.8961 - val_loss: 0.3848 - val_categorical_accuracy: 0.8503\n",
            "\n",
            "Epoch 00003: val_categorical_accuracy improved from 0.82854 to 0.85035, saving model to TL_VGG16/210119_0800/weights/ep_03_ls_0.85.h5\n",
            "Epoch 4/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.2622 - categorical_accuracy: 0.9048 - val_loss: 0.3503 - val_categorical_accuracy: 0.8662\n",
            "\n",
            "Epoch 00004: val_categorical_accuracy improved from 0.85035 to 0.86620, saving model to TL_VGG16/210119_0800/weights/ep_04_ls_0.87.h5\n",
            "Epoch 5/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.2260 - categorical_accuracy: 0.9148 - val_loss: 0.3499 - val_categorical_accuracy: 0.8781\n",
            "\n",
            "Epoch 00005: val_categorical_accuracy improved from 0.86620 to 0.87810, saving model to TL_VGG16/210119_0800/weights/ep_05_ls_0.88.h5\n",
            "Epoch 6/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.2055 - categorical_accuracy: 0.9260 - val_loss: 0.3442 - val_categorical_accuracy: 0.8741\n",
            "\n",
            "Epoch 00006: val_categorical_accuracy did not improve from 0.87810\n",
            "Epoch 7/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.2036 - categorical_accuracy: 0.9272 - val_loss: 0.3464 - val_categorical_accuracy: 0.8632\n",
            "\n",
            "Epoch 00007: val_categorical_accuracy did not improve from 0.87810\n",
            "Epoch 8/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.1718 - categorical_accuracy: 0.9307 - val_loss: 0.2932 - val_categorical_accuracy: 0.8811\n",
            "\n",
            "Epoch 00008: val_categorical_accuracy improved from 0.87810 to 0.88107, saving model to TL_VGG16/210119_0800/weights/ep_08_ls_0.88.h5\n",
            "Epoch 9/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.1781 - categorical_accuracy: 0.9327 - val_loss: 0.2886 - val_categorical_accuracy: 0.8920\n",
            "\n",
            "Epoch 00009: val_categorical_accuracy improved from 0.88107 to 0.89197, saving model to TL_VGG16/210119_0800/weights/ep_09_ls_0.89.h5\n",
            "Epoch 10/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.1752 - categorical_accuracy: 0.9356 - val_loss: 0.2375 - val_categorical_accuracy: 0.9128\n",
            "\n",
            "Epoch 00010: val_categorical_accuracy improved from 0.89197 to 0.91278, saving model to TL_VGG16/210119_0800/weights/ep_10_ls_0.91.h5\n",
            "Epoch 11/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.1634 - categorical_accuracy: 0.9381 - val_loss: 0.3265 - val_categorical_accuracy: 0.8573\n",
            "\n",
            "Epoch 00011: val_categorical_accuracy did not improve from 0.91278\n",
            "Epoch 12/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.1768 - categorical_accuracy: 0.9313 - val_loss: 0.2900 - val_categorical_accuracy: 0.9326\n",
            "\n",
            "Epoch 00012: val_categorical_accuracy improved from 0.91278 to 0.93261, saving model to TL_VGG16/210119_0800/weights/ep_12_ls_0.93.h5\n",
            "Epoch 13/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.1543 - categorical_accuracy: 0.9429 - val_loss: 0.3317 - val_categorical_accuracy: 0.8840\n",
            "\n",
            "Epoch 00013: val_categorical_accuracy did not improve from 0.93261\n",
            "Epoch 14/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.1463 - categorical_accuracy: 0.9402 - val_loss: 0.2304 - val_categorical_accuracy: 0.9197\n",
            "\n",
            "Epoch 00014: val_categorical_accuracy did not improve from 0.93261\n",
            "Epoch 15/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.1409 - categorical_accuracy: 0.9472 - val_loss: 0.2736 - val_categorical_accuracy: 0.9009\n",
            "\n",
            "Epoch 00015: val_categorical_accuracy did not improve from 0.93261\n",
            "Epoch 16/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.1207 - categorical_accuracy: 0.9564 - val_loss: 0.2993 - val_categorical_accuracy: 0.8920\n",
            "\n",
            "Epoch 00016: val_categorical_accuracy did not improve from 0.93261\n",
            "Epoch 17/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.1436 - categorical_accuracy: 0.9453 - val_loss: 0.3041 - val_categorical_accuracy: 0.8959\n",
            "\n",
            "Epoch 00017: val_categorical_accuracy did not improve from 0.93261\n",
            "Epoch 18/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.1502 - categorical_accuracy: 0.9452 - val_loss: 0.2347 - val_categorical_accuracy: 0.9316\n",
            "\n",
            "Epoch 00018: val_categorical_accuracy did not improve from 0.93261\n",
            "Epoch 19/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.1088 - categorical_accuracy: 0.9597 - val_loss: 0.2291 - val_categorical_accuracy: 0.9346\n",
            "\n",
            "Epoch 00019: val_categorical_accuracy improved from 0.93261 to 0.93459, saving model to TL_VGG16/210119_0800/weights/ep_19_ls_0.93.h5\n",
            "Epoch 20/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.1122 - categorical_accuracy: 0.9562 - val_loss: 0.2300 - val_categorical_accuracy: 0.9128\n",
            "\n",
            "Epoch 00020: val_categorical_accuracy did not improve from 0.93459\n",
            "Epoch 21/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0945 - categorical_accuracy: 0.9648 - val_loss: 0.2228 - val_categorical_accuracy: 0.9356\n",
            "\n",
            "Epoch 00021: val_categorical_accuracy improved from 0.93459 to 0.93558, saving model to TL_VGG16/210119_0800/weights/ep_21_ls_0.94.h5\n",
            "Epoch 22/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0951 - categorical_accuracy: 0.9654 - val_loss: 0.1994 - val_categorical_accuracy: 0.9415\n",
            "\n",
            "Epoch 00022: val_categorical_accuracy improved from 0.93558 to 0.94153, saving model to TL_VGG16/210119_0800/weights/ep_22_ls_0.94.h5\n",
            "Epoch 23/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.0875 - categorical_accuracy: 0.9684 - val_loss: 0.2202 - val_categorical_accuracy: 0.9366\n",
            "\n",
            "Epoch 00023: val_categorical_accuracy did not improve from 0.94153\n",
            "Epoch 24/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0904 - categorical_accuracy: 0.9668 - val_loss: 0.2314 - val_categorical_accuracy: 0.9425\n",
            "\n",
            "Epoch 00024: val_categorical_accuracy improved from 0.94153 to 0.94252, saving model to TL_VGG16/210119_0800/weights/ep_24_ls_0.94.h5\n",
            "Epoch 25/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0930 - categorical_accuracy: 0.9687 - val_loss: 0.1965 - val_categorical_accuracy: 0.9465\n",
            "\n",
            "Epoch 00025: val_categorical_accuracy improved from 0.94252 to 0.94648, saving model to TL_VGG16/210119_0800/weights/ep_25_ls_0.95.h5\n",
            "Epoch 26/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.0789 - categorical_accuracy: 0.9721 - val_loss: 0.1851 - val_categorical_accuracy: 0.9475\n",
            "\n",
            "Epoch 00026: val_categorical_accuracy improved from 0.94648 to 0.94747, saving model to TL_VGG16/210119_0800/weights/ep_26_ls_0.95.h5\n",
            "Epoch 27/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.0922 - categorical_accuracy: 0.9640 - val_loss: 0.2307 - val_categorical_accuracy: 0.9326\n",
            "\n",
            "Epoch 00027: val_categorical_accuracy did not improve from 0.94747\n",
            "Epoch 28/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0967 - categorical_accuracy: 0.9657 - val_loss: 0.2585 - val_categorical_accuracy: 0.9177\n",
            "\n",
            "Epoch 00028: val_categorical_accuracy did not improve from 0.94747\n",
            "Epoch 29/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0955 - categorical_accuracy: 0.9642 - val_loss: 0.3199 - val_categorical_accuracy: 0.9049\n",
            "\n",
            "Epoch 00029: val_categorical_accuracy did not improve from 0.94747\n",
            "Epoch 30/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0847 - categorical_accuracy: 0.9674 - val_loss: 0.1787 - val_categorical_accuracy: 0.9485\n",
            "\n",
            "Epoch 00030: val_categorical_accuracy improved from 0.94747 to 0.94846, saving model to TL_VGG16/210119_0800/weights/ep_30_ls_0.95.h5\n",
            "Epoch 31/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.0843 - categorical_accuracy: 0.9669 - val_loss: 0.1719 - val_categorical_accuracy: 0.9495\n",
            "\n",
            "Epoch 00031: val_categorical_accuracy improved from 0.94846 to 0.94945, saving model to TL_VGG16/210119_0800/weights/ep_31_ls_0.95.h5\n",
            "Epoch 32/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0866 - categorical_accuracy: 0.9701 - val_loss: 0.1987 - val_categorical_accuracy: 0.9435\n",
            "\n",
            "Epoch 00032: val_categorical_accuracy did not improve from 0.94945\n",
            "Epoch 33/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0725 - categorical_accuracy: 0.9743 - val_loss: 0.2426 - val_categorical_accuracy: 0.9495\n",
            "\n",
            "Epoch 00033: val_categorical_accuracy did not improve from 0.94945\n",
            "Epoch 34/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0657 - categorical_accuracy: 0.9721 - val_loss: 0.2436 - val_categorical_accuracy: 0.9316\n",
            "\n",
            "Epoch 00034: val_categorical_accuracy did not improve from 0.94945\n",
            "Epoch 35/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0840 - categorical_accuracy: 0.9708 - val_loss: 0.2493 - val_categorical_accuracy: 0.9247\n",
            "\n",
            "Epoch 00035: val_categorical_accuracy did not improve from 0.94945\n",
            "Epoch 36/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0585 - categorical_accuracy: 0.9770 - val_loss: 0.1883 - val_categorical_accuracy: 0.9554\n",
            "\n",
            "Epoch 00036: val_categorical_accuracy improved from 0.94945 to 0.95540, saving model to TL_VGG16/210119_0800/weights/ep_36_ls_0.96.h5\n",
            "Epoch 37/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0800 - categorical_accuracy: 0.9687 - val_loss: 0.2338 - val_categorical_accuracy: 0.9306\n",
            "\n",
            "Epoch 00037: val_categorical_accuracy did not improve from 0.95540\n",
            "Epoch 38/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0719 - categorical_accuracy: 0.9691 - val_loss: 0.2554 - val_categorical_accuracy: 0.9376\n",
            "\n",
            "Epoch 00038: val_categorical_accuracy did not improve from 0.95540\n",
            "Epoch 39/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0794 - categorical_accuracy: 0.9694 - val_loss: 0.2135 - val_categorical_accuracy: 0.9415\n",
            "\n",
            "Epoch 00039: val_categorical_accuracy did not improve from 0.95540\n",
            "Epoch 40/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0739 - categorical_accuracy: 0.9751 - val_loss: 0.1793 - val_categorical_accuracy: 0.9524\n",
            "\n",
            "Epoch 00040: val_categorical_accuracy did not improve from 0.95540\n",
            "Epoch 41/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0711 - categorical_accuracy: 0.9766 - val_loss: 0.1673 - val_categorical_accuracy: 0.9604\n",
            "\n",
            "Epoch 00041: val_categorical_accuracy improved from 0.95540 to 0.96036, saving model to TL_VGG16/210119_0800/weights/ep_41_ls_0.96.h5\n",
            "Epoch 42/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0670 - categorical_accuracy: 0.9775 - val_loss: 0.2152 - val_categorical_accuracy: 0.9346\n",
            "\n",
            "Epoch 00042: val_categorical_accuracy did not improve from 0.96036\n",
            "Epoch 43/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.0585 - categorical_accuracy: 0.9779 - val_loss: 0.2208 - val_categorical_accuracy: 0.9395\n",
            "\n",
            "Epoch 00043: val_categorical_accuracy did not improve from 0.96036\n",
            "Epoch 44/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0785 - categorical_accuracy: 0.9686 - val_loss: 0.1913 - val_categorical_accuracy: 0.9485\n",
            "\n",
            "Epoch 00044: val_categorical_accuracy did not improve from 0.96036\n",
            "Epoch 45/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0677 - categorical_accuracy: 0.9778 - val_loss: 0.1919 - val_categorical_accuracy: 0.9485\n",
            "\n",
            "Epoch 00045: val_categorical_accuracy did not improve from 0.96036\n",
            "Epoch 46/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0809 - categorical_accuracy: 0.9704 - val_loss: 0.2190 - val_categorical_accuracy: 0.9524\n",
            "\n",
            "Epoch 00046: val_categorical_accuracy did not improve from 0.96036\n",
            "Epoch 47/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.0684 - categorical_accuracy: 0.9804 - val_loss: 0.2433 - val_categorical_accuracy: 0.9554\n",
            "\n",
            "Epoch 00047: val_categorical_accuracy did not improve from 0.96036\n",
            "Epoch 48/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0642 - categorical_accuracy: 0.9757 - val_loss: 0.1883 - val_categorical_accuracy: 0.9564\n",
            "\n",
            "Epoch 00048: val_categorical_accuracy did not improve from 0.96036\n",
            "Epoch 49/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0580 - categorical_accuracy: 0.9778 - val_loss: 0.2530 - val_categorical_accuracy: 0.9425\n",
            "\n",
            "Epoch 00049: val_categorical_accuracy did not improve from 0.96036\n",
            "Epoch 50/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0649 - categorical_accuracy: 0.9751 - val_loss: 0.2069 - val_categorical_accuracy: 0.9554\n",
            "\n",
            "Epoch 00050: val_categorical_accuracy did not improve from 0.96036\n",
            "Epoch 51/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0676 - categorical_accuracy: 0.9741 - val_loss: 0.2099 - val_categorical_accuracy: 0.9574\n",
            "\n",
            "Epoch 00051: val_categorical_accuracy did not improve from 0.96036\n",
            "Epoch 52/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0487 - categorical_accuracy: 0.9818 - val_loss: 0.1950 - val_categorical_accuracy: 0.9594\n",
            "\n",
            "Epoch 00052: val_categorical_accuracy did not improve from 0.96036\n",
            "Epoch 53/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0532 - categorical_accuracy: 0.9803 - val_loss: 0.2015 - val_categorical_accuracy: 0.9584\n",
            "\n",
            "Epoch 00053: val_categorical_accuracy did not improve from 0.96036\n",
            "Epoch 54/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0604 - categorical_accuracy: 0.9790 - val_loss: 0.2000 - val_categorical_accuracy: 0.9584\n",
            "\n",
            "Epoch 00054: val_categorical_accuracy did not improve from 0.96036\n",
            "Epoch 55/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0418 - categorical_accuracy: 0.9858 - val_loss: 0.2415 - val_categorical_accuracy: 0.9544\n",
            "\n",
            "Epoch 00055: val_categorical_accuracy did not improve from 0.96036\n",
            "Epoch 56/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0579 - categorical_accuracy: 0.9784 - val_loss: 0.1805 - val_categorical_accuracy: 0.9544\n",
            "\n",
            "Epoch 00056: val_categorical_accuracy did not improve from 0.96036\n",
            "Epoch 57/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0556 - categorical_accuracy: 0.9762 - val_loss: 0.2077 - val_categorical_accuracy: 0.9574\n",
            "\n",
            "Epoch 00057: val_categorical_accuracy did not improve from 0.96036\n",
            "Epoch 58/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0528 - categorical_accuracy: 0.9778 - val_loss: 0.2084 - val_categorical_accuracy: 0.9544\n",
            "\n",
            "Epoch 00058: val_categorical_accuracy did not improve from 0.96036\n",
            "Epoch 59/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0540 - categorical_accuracy: 0.9809 - val_loss: 0.2436 - val_categorical_accuracy: 0.9445\n",
            "\n",
            "Epoch 00059: val_categorical_accuracy did not improve from 0.96036\n",
            "Epoch 60/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.0423 - categorical_accuracy: 0.9857 - val_loss: 0.2435 - val_categorical_accuracy: 0.9514\n",
            "\n",
            "Epoch 00060: val_categorical_accuracy did not improve from 0.96036\n",
            "Epoch 61/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.0491 - categorical_accuracy: 0.9836 - val_loss: 0.2669 - val_categorical_accuracy: 0.9356\n",
            "\n",
            "Epoch 00061: val_categorical_accuracy did not improve from 0.96036\n",
            "Epoch 62/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.0364 - categorical_accuracy: 0.9885 - val_loss: 0.2466 - val_categorical_accuracy: 0.9326\n",
            "\n",
            "Epoch 00062: val_categorical_accuracy did not improve from 0.96036\n",
            "Epoch 63/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.0428 - categorical_accuracy: 0.9845 - val_loss: 0.1864 - val_categorical_accuracy: 0.9683\n",
            "\n",
            "Epoch 00063: val_categorical_accuracy improved from 0.96036 to 0.96829, saving model to TL_VGG16/210119_0800/weights/ep_63_ls_0.97.h5\n",
            "Epoch 64/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.0382 - categorical_accuracy: 0.9866 - val_loss: 0.2333 - val_categorical_accuracy: 0.9376\n",
            "\n",
            "Epoch 00064: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 65/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0774 - categorical_accuracy: 0.9747 - val_loss: 0.2383 - val_categorical_accuracy: 0.9504\n",
            "\n",
            "Epoch 00065: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 66/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0671 - categorical_accuracy: 0.9789 - val_loss: 0.1531 - val_categorical_accuracy: 0.9653\n",
            "\n",
            "Epoch 00066: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 67/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.0426 - categorical_accuracy: 0.9872 - val_loss: 0.2324 - val_categorical_accuracy: 0.9544\n",
            "\n",
            "Epoch 00067: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 68/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.0483 - categorical_accuracy: 0.9812 - val_loss: 0.2154 - val_categorical_accuracy: 0.9564\n",
            "\n",
            "Epoch 00068: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 69/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.0463 - categorical_accuracy: 0.9839 - val_loss: 0.2549 - val_categorical_accuracy: 0.9485\n",
            "\n",
            "Epoch 00069: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 70/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0476 - categorical_accuracy: 0.9815 - val_loss: 0.2231 - val_categorical_accuracy: 0.9564\n",
            "\n",
            "Epoch 00070: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 71/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0479 - categorical_accuracy: 0.9821 - val_loss: 0.2427 - val_categorical_accuracy: 0.9554\n",
            "\n",
            "Epoch 00071: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 72/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0437 - categorical_accuracy: 0.9846 - val_loss: 0.1877 - val_categorical_accuracy: 0.9574\n",
            "\n",
            "Epoch 00072: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 73/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0348 - categorical_accuracy: 0.9878 - val_loss: 0.2704 - val_categorical_accuracy: 0.9534\n",
            "\n",
            "Epoch 00073: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 74/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0475 - categorical_accuracy: 0.9856 - val_loss: 0.2377 - val_categorical_accuracy: 0.9475\n",
            "\n",
            "Epoch 00074: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 75/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0392 - categorical_accuracy: 0.9833 - val_loss: 0.3074 - val_categorical_accuracy: 0.9613\n",
            "\n",
            "Epoch 00075: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 76/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0369 - categorical_accuracy: 0.9876 - val_loss: 0.2253 - val_categorical_accuracy: 0.9554\n",
            "\n",
            "Epoch 00076: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 77/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0320 - categorical_accuracy: 0.9848 - val_loss: 0.2188 - val_categorical_accuracy: 0.9514\n",
            "\n",
            "Epoch 00077: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 78/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.0373 - categorical_accuracy: 0.9883 - val_loss: 0.2538 - val_categorical_accuracy: 0.9504\n",
            "\n",
            "Epoch 00078: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 79/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.0463 - categorical_accuracy: 0.9818 - val_loss: 0.2025 - val_categorical_accuracy: 0.9554\n",
            "\n",
            "Epoch 00079: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 80/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0421 - categorical_accuracy: 0.9853 - val_loss: 0.2067 - val_categorical_accuracy: 0.9514\n",
            "\n",
            "Epoch 00080: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 81/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.0464 - categorical_accuracy: 0.9835 - val_loss: 0.3084 - val_categorical_accuracy: 0.9514\n",
            "\n",
            "Epoch 00081: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 82/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0476 - categorical_accuracy: 0.9831 - val_loss: 0.2256 - val_categorical_accuracy: 0.9604\n",
            "\n",
            "Epoch 00082: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 83/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.0391 - categorical_accuracy: 0.9867 - val_loss: 0.2020 - val_categorical_accuracy: 0.9633\n",
            "\n",
            "Epoch 00083: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 84/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.0421 - categorical_accuracy: 0.9823 - val_loss: 0.2421 - val_categorical_accuracy: 0.9495\n",
            "\n",
            "Epoch 00084: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 85/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.0396 - categorical_accuracy: 0.9891 - val_loss: 0.1897 - val_categorical_accuracy: 0.9663\n",
            "\n",
            "Epoch 00085: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 86/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.0373 - categorical_accuracy: 0.9863 - val_loss: 0.2326 - val_categorical_accuracy: 0.9613\n",
            "\n",
            "Epoch 00086: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 87/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.0224 - categorical_accuracy: 0.9933 - val_loss: 0.2569 - val_categorical_accuracy: 0.9653\n",
            "\n",
            "Epoch 00087: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 88/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.0286 - categorical_accuracy: 0.9899 - val_loss: 0.2083 - val_categorical_accuracy: 0.9653\n",
            "\n",
            "Epoch 00088: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 89/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.0413 - categorical_accuracy: 0.9857 - val_loss: 0.2094 - val_categorical_accuracy: 0.9613\n",
            "\n",
            "Epoch 00089: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 90/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0317 - categorical_accuracy: 0.9915 - val_loss: 0.2149 - val_categorical_accuracy: 0.9534\n",
            "\n",
            "Epoch 00090: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 91/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0240 - categorical_accuracy: 0.9908 - val_loss: 0.1880 - val_categorical_accuracy: 0.9653\n",
            "\n",
            "Epoch 00091: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 92/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0250 - categorical_accuracy: 0.9889 - val_loss: 0.2277 - val_categorical_accuracy: 0.9574\n",
            "\n",
            "Epoch 00092: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 93/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0334 - categorical_accuracy: 0.9875 - val_loss: 0.2765 - val_categorical_accuracy: 0.9534\n",
            "\n",
            "Epoch 00093: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 94/500\n",
            "64/64 [==============================] - 77s 1s/step - loss: 0.0357 - categorical_accuracy: 0.9867 - val_loss: 0.2042 - val_categorical_accuracy: 0.9554\n",
            "\n",
            "Epoch 00094: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 95/500\n",
            "64/64 [==============================] - 78s 1s/step - loss: 0.0291 - categorical_accuracy: 0.9893 - val_loss: 0.2714 - val_categorical_accuracy: 0.9465\n",
            "\n",
            "Epoch 00095: val_categorical_accuracy did not improve from 0.96829\n",
            "Epoch 00095: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWzAwLFQRZO-"
      },
      "source": [
        "model.save('VGG16.h5')\r\n",
        "\r\n",
        "from google.colab import files\r\n",
        "# files.download('Transfer_Training.h5')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHAXfDkDuH0X"
      },
      "source": [
        "# Review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpQ0_6xiO32P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "2e752536-561c-4410-8bfe-4566bd09f4f9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history.history['loss']\n",
        "acc = history.history['categorical_accuracy']\n",
        "epochs = range(1, len(loss)+1)\n",
        "val_loss = history.history['val_loss']\n",
        "val_acc = history.history['val_categorical_accuracy']\n",
        "\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
        "ax[0].plot(epochs, loss, 'b', label='loss')\n",
        "ax[0].plot(epochs, val_loss, 'r', label='validation loss')\n",
        "ax[0].legend()\n",
        "ax[1].plot(epochs, acc, 'b', label='accuracy')\n",
        "ax[1].plot(epochs, val_acc, 'r', label='validation accuracy')\n",
        "ax[1].legend()\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc5L-ZvCuJyf"
      },
      "source": [
        "# Valid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3pubotFGOSA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e644d9b-52b8-428a-e96b-b8bc2596dc65"
      },
      "source": [
        "valid_datagen = ImageDataGenerator(\r\n",
        "    rescale=1./255,\r\n",
        "    preprocessing_function=preprocess_input\r\n",
        ")\r\n",
        "\r\n",
        "evaluate_itr = valid_datagen.flow_from_directory(\r\n",
        "    './classify',\r\n",
        "    target_size=(256, 256),\r\n",
        "    batch_size=64,\r\n",
        "    class_mode='categorical',\r\n",
        "    shuffle=False\r\n",
        ")\r\n",
        "\r\n",
        "loss, accuracy = model.evaluate_generator(evaluate_itr)\r\n",
        "print(f'loss = {loss:.2f}')\r\n",
        "print(f'accuracy = {accuracy:.2f}')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5056 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss = 0.11\n",
            "accuracy = 0.97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVYHpZQ2HIB_",
        "outputId": "3bfe4ab0-5640-4c8e-9e3c-e6985a3118ea"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "# labels\r\n",
        "labels = evaluate_itr.class_indices\r\n",
        "\r\n",
        "# then use predict_geneorator to predict the result base on model\r\n",
        "evaluate_itr.reset()\r\n",
        "pred = model.predict_generator(evaluate_itr, verbose=1)\r\n",
        "\r\n",
        "# prediction from model\r\n",
        "predicted_class_indices = np.argmax(pred, axis=1)\r\n",
        "# real results in training set\r\n",
        "true_label= evaluate_itr.classes"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 25s 316ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SASG2NmquPvr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "7fa2fd25-17b1-4923-d037-e46d6d438bd8"
      },
      "source": [
        "#使用pd.crosstab来简单画出混淆矩阵\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "table = pd.crosstab(predicted_class_indices, true_label,colnames=['predict'], rownames=['label'])\r\n",
        "table"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>predict</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1248</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>965</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>170</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>97</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>735</td>\n",
              "      <td>32</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>441</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1280</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "predict     0    1    2    3    4     5\n",
              "label                                  \n",
              "0        1248    4   29    1    0     0\n",
              "1           1  965    0   19    7     0\n",
              "2           2    0  170    0    0     0\n",
              "3          97   10    1  735   32     8\n",
              "4           0    1    0    1  441     0\n",
              "5           0    4    0    0    0  1280"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}