{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.9 64-bit ('python37': conda)",
      "metadata": {
        "interpreter": {
          "hash": "56918090559b2dfb924586d334310b74e75434cb73f2473ccf8876bfcc1690fc"
        }
      }
    },
    "colab": {
      "name": "InceptionV3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMaLFwh4Rzrb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe232a58-4ce3-46e1-cde1-854032cc678f"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jan 20 01:06:56 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkDzayYbO32E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "684961c7-2033-4ac0-ad63-567c1a233e51"
      },
      "source": [
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDYKQwwMRgO5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a570c0ff-43bc-48fd-e690-74c46dc65aa9"
      },
      "source": [
        "os.chdir('/content/drive/My Drive/AOI') #切換該目錄\r\n",
        "os.listdir() #確認目錄內容"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test_images.zip',\n",
              " 'classify',\n",
              " 'Model.h5',\n",
              " 'test_images',\n",
              " 'csv',\n",
              " 'QC_Sampling.ipynb',\n",
              " 'QC_Diff_of_Predictions.ipynb',\n",
              " 'TL_VGG16',\n",
              " 'Model.ipynb',\n",
              " 'QC_toCSV.ipynb',\n",
              " 'TL_InceptionV3',\n",
              " 'InceptionV3.h5',\n",
              " 'TL_ResNet50',\n",
              " 'VGG16.ipynb',\n",
              " 'VGG16-valAcc9683.h5',\n",
              " 'ResNet50.h5',\n",
              " 'image_compare.ipynb',\n",
              " 'ResNet50.ipynb',\n",
              " 'Model_Predict.ipynb',\n",
              " 'InceptionV3.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej_slIVpO32I"
      },
      "source": [
        "# input 為 灰階 256 * 256 圖像\n",
        "# 灰階 為 1 通道\n",
        "input_shape = (256, 256, 3)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e85Flb0xO32J"
      },
      "source": [
        "# Model building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ja7anJSO32J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a01c7e7-55da-4a48-9b01-66d7350cc4e7"
      },
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# transfer trainging\n",
        "# need not to include the output layer, we will redefine it later\n",
        "inceptionV3 = InceptionV3(include_top=False, input_shape=input_shape)\n",
        "inceptionV3.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 127, 127, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 127, 127, 32) 96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 127, 127, 32) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 125, 125, 32) 9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 125, 125, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 125, 125, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 125, 125, 64) 18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 125, 125, 64) 192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 125, 125, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 62, 62, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 62, 62, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 62, 62, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 62, 62, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 60, 60, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 60, 60, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 60, 60, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 29, 29, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 29, 29, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 29, 29, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 29, 29, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 29, 29, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 29, 29, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 29, 29, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 29, 29, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 29, 29, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 29, 29, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 29, 29, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 29, 29, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 29, 29, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 29, 29, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 29, 29, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 29, 29, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 29, 29, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 29, 29, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 29, 29, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 29, 29, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 29, 29, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 29, 29, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 29, 29, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 29, 29, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 29, 29, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 29, 29, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 29, 29, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 29, 29, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 29, 29, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 29, 29, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 29, 29, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 29, 29, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 29, 29, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 29, 29, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 29, 29, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 29, 29, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 29, 29, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 29, 29, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 29, 29, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 29, 29, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 29, 29, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 29, 29, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 29, 29, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 29, 29, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 29, 29, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 29, 29, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 29, 29, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 29, 29, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 29, 29, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 29, 29, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 29, 29, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 29, 29, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 29, 29, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 29, 29, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 29, 29, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 29, 29, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 29, 29, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 29, 29, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 29, 29, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 29, 29, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 29, 29, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 29, 29, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 29, 29, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 29, 29, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 29, 29, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 29, 29, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 29, 29, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 29, 29, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 29, 29, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 29, 29, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 29, 29, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 29, 29, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 29, 29, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 29, 29, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 29, 29, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 29, 29, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 14, 14, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 14, 14, 96)   82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 14, 14, 384)  1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 14, 14, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 384)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 14, 14, 768)  0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 14, 14, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 14, 14, 128)  384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 128)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 14, 14, 128)  114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 14, 14, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 14, 14, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 14, 14, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 14, 14, 128)  384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 14, 14, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 128)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 14, 14, 128)  114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 14, 14, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 14, 14, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 14, 14, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 14, 14, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 14, 14, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 14, 14, 192)  172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 14, 14, 192)  172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 14, 14, 192)  576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 14, 14, 192)  576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 14, 14, 192)  576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 14, 14, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 192)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 192)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 192)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 14, 14, 768)  0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 14, 14, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 14, 14, 160)  480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 14, 14, 160)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 14, 14, 160)  179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 14, 14, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 14, 14, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 14, 14, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 14, 14, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 14, 14, 160)  480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 14, 14, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 14, 14, 160)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 14, 14, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 14, 14, 160)  179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 14, 14, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 14, 14, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 14, 14, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 14, 14, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 14, 14, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 14, 14, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 14, 14, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 14, 14, 192)  215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 14, 14, 192)  215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 14, 14, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 14, 14, 192)  576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 14, 14, 192)  576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 14, 14, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 14, 14, 192)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 14, 14, 192)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 14, 14, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 14, 14, 768)  0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 14, 14, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 14, 14, 160)  480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 14, 14, 160)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 14, 14, 160)  179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 14, 14, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 14, 14, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 14, 14, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 14, 14, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 14, 14, 160)  480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 14, 14, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 14, 14, 160)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 14, 14, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 14, 14, 160)  179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 14, 14, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 14, 14, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 14, 14, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 14, 14, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 14, 14, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 14, 14, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 14, 14, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 14, 14, 192)  215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 14, 14, 192)  215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 14, 14, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 14, 14, 192)  576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 14, 14, 192)  576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 14, 14, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 14, 14, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 14, 14, 192)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 14, 14, 192)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 14, 14, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 14, 14, 768)  0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 14, 14, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 14, 14, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 14, 14, 192)  258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 14, 14, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 14, 14, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 14, 14, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 14, 14, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 14, 14, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 14, 14, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 14, 14, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 14, 14, 192)  258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 14, 14, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 14, 14, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 14, 14, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 14, 14, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 14, 14, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 14, 14, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 14, 14, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 14, 14, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 14, 14, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 14, 14, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 14, 14, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 14, 14, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 14, 14, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 14, 14, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 14, 14, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 14, 14, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 14, 14, 768)  0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 14, 14, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 14, 14, 192)  576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 14, 14, 192)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 14, 14, 192)  258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 14, 14, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 14, 14, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 14, 14, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 14, 14, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 14, 14, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 14, 14, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 14, 14, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 14, 14, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 6, 6, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 6, 6, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 6, 6, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 6, 6, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 6, 6, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 6, 6, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 6, 6, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 6, 6, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 6, 6, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 6, 6, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 6, 6, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 6, 6, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 6, 6, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 6, 6, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 6, 6, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 6, 6, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 6, 6, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 6, 6, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 6, 6, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 6, 6, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 6, 6, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 6, 6, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 6, 6, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 6, 6, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 6, 6, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 6, 6, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 6, 6, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 6, 6, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 6, 6, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 6, 6, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 6, 6, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 6, 6, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 6, 6, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 6, 6, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 6, 6, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 6, 6, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 6, 6, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 6, 6, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 6, 6, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 6, 6, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 6, 6, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 6, 6, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 6, 6, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 6, 6, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 6, 6, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 6, 6, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 6, 6, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 6, 6, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 6, 6, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 6, 6, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 6, 6, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 6, 6, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 6, 6, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 6, 6, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 6, 6, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 6, 6, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 6, 6, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 6, 6, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 6, 6, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 6, 6, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 6, 6, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 6, 6, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 6, 6, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 6, 6, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 6, 6, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 6, 6, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 6, 6, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 6, 6, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 6, 6, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 6, 6, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpzHPBFwO32K"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import initializers\n",
        "from keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "def build_model(inceptionV3):\n",
        "\n",
        "    base_model = inceptionV3\n",
        "    \n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # 增加 DropOut layer\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    # 增加 Dense layer，以 softmax 產生個類別的機率值\n",
        "    x = Dense(6, activation='softmax', name='softmax')(x)\n",
        "\n",
        "    # x = base_model.output\n",
        "    # x = GlobalAveragePooling2D()(x)\n",
        "    # # We add a fully-connected layer\n",
        "    # x = Dense(512, activation='relu', kernel_initializer=initializers.VarianceScaling(scale=2.0))(x)\n",
        "    # x = Dropout(0.25)(x)\n",
        "    # # redefine the output layer to 6 class(AOI )\n",
        "    # x = Dense(6, activation='sigmoid')(x)\n",
        "\n",
        "    model= Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "    #We freeze the model excepted the added layers\n",
        "    #279 is number of mixed 9 layer\n",
        "    #248 is number of mixed 8 layer\n",
        "\n",
        "    for layer in model.layers[:280]:\n",
        "        layer.trainable = False\n",
        "    for layer in model.layers[280:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I3Aw1rUO32L"
      },
      "source": [
        "model = build_model(inceptionV3)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDNkK2UHO32L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20f7dccb-7c8b-423d-a832-235111fdc8e3"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "model.compile(\n",
        "    loss = 'categorical_crossentropy',\n",
        "    # optimizer=SGD(lr=1e-4, momentum=0.9),\n",
        "    optimizer=Adam(lr=1e-4),\n",
        "    metrics=['categorical_accuracy']\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 127, 127, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 127, 127, 32) 96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 127, 127, 32) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 125, 125, 32) 9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 125, 125, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 125, 125, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 125, 125, 64) 18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 125, 125, 64) 192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 125, 125, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 62, 62, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 62, 62, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 62, 62, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 62, 62, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 60, 60, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 60, 60, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 60, 60, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 29, 29, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 29, 29, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 29, 29, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 29, 29, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 29, 29, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 29, 29, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 29, 29, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 29, 29, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 29, 29, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 29, 29, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 29, 29, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 29, 29, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 29, 29, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 29, 29, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 29, 29, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 29, 29, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 29, 29, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 29, 29, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 29, 29, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 29, 29, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 29, 29, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 29, 29, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 29, 29, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 29, 29, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 29, 29, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 29, 29, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 29, 29, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 29, 29, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 29, 29, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 29, 29, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 29, 29, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 29, 29, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 29, 29, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 29, 29, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 29, 29, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 29, 29, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 29, 29, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 29, 29, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 29, 29, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 29, 29, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 29, 29, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 29, 29, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 29, 29, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 29, 29, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 29, 29, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 29, 29, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 29, 29, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 29, 29, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 29, 29, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 29, 29, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 29, 29, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 29, 29, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 29, 29, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 29, 29, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 29, 29, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 29, 29, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 29, 29, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 29, 29, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 29, 29, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 29, 29, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 29, 29, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 29, 29, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 29, 29, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 29, 29, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 29, 29, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 29, 29, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 29, 29, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 29, 29, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 29, 29, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 29, 29, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 29, 29, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 29, 29, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 29, 29, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 29, 29, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 29, 29, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 29, 29, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 14, 14, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 14, 14, 96)   82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 14, 14, 384)  1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 14, 14, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 384)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 14, 14, 768)  0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 14, 14, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 14, 14, 128)  384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 128)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 14, 14, 128)  114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 14, 14, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 14, 14, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 14, 14, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 14, 14, 128)  384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 14, 14, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 128)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 14, 14, 128)  114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 14, 14, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 14, 14, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 14, 14, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 14, 14, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 14, 14, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 14, 14, 192)  172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 14, 14, 192)  172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 14, 14, 192)  576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 14, 14, 192)  576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 14, 14, 192)  576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 14, 14, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 192)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 192)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 192)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 14, 14, 768)  0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 14, 14, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 14, 14, 160)  480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 14, 14, 160)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 14, 14, 160)  179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 14, 14, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 14, 14, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 14, 14, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 14, 14, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 14, 14, 160)  480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 14, 14, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 14, 14, 160)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 14, 14, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 14, 14, 160)  179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 14, 14, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 14, 14, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 14, 14, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 14, 14, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 14, 14, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 14, 14, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 14, 14, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 14, 14, 192)  215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 14, 14, 192)  215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 14, 14, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 14, 14, 192)  576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 14, 14, 192)  576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 14, 14, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 14, 14, 192)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 14, 14, 192)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 14, 14, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 14, 14, 768)  0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 14, 14, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 14, 14, 160)  480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 14, 14, 160)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 14, 14, 160)  179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 14, 14, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 14, 14, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 14, 14, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 14, 14, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 14, 14, 160)  480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 14, 14, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 14, 14, 160)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 14, 14, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 14, 14, 160)  179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 14, 14, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 14, 14, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 14, 14, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 14, 14, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 14, 14, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 14, 14, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 14, 14, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 14, 14, 192)  215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 14, 14, 192)  215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 14, 14, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 14, 14, 192)  576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 14, 14, 192)  576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 14, 14, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 14, 14, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 14, 14, 192)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 14, 14, 192)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 14, 14, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 14, 14, 768)  0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 14, 14, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 14, 14, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 14, 14, 192)  258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 14, 14, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 14, 14, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 14, 14, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 14, 14, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 14, 14, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 14, 14, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 14, 14, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 14, 14, 192)  258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 14, 14, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 14, 14, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 14, 14, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 14, 14, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 14, 14, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 14, 14, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 14, 14, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 14, 14, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 14, 14, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 14, 14, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 14, 14, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 14, 14, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 14, 14, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 14, 14, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 14, 14, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 14, 14, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 14, 14, 768)  0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 14, 14, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 14, 14, 192)  576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 14, 14, 192)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 14, 14, 192)  258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 14, 14, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 14, 14, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 14, 14, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 14, 14, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 14, 14, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 14, 14, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 14, 14, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 14, 14, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 6, 6, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 6, 6, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 6, 6, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 6, 6, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 6, 6, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 6, 6, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 6, 6, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 6, 6, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 6, 6, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 6, 6, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 6, 6, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 6, 6, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 6, 6, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 6, 6, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 6, 6, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 6, 6, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 6, 6, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 6, 6, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 6, 6, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 6, 6, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 6, 6, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 6, 6, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 6, 6, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 6, 6, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 6, 6, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 6, 6, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 6, 6, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 6, 6, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 6, 6, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 6, 6, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 6, 6, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 6, 6, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 6, 6, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 6, 6, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 6, 6, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 6, 6, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 6, 6, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 6, 6, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 6, 6, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 6, 6, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 6, 6, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 6, 6, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 6, 6, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 6, 6, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 6, 6, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 6, 6, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 6, 6, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 6, 6, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 6, 6, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 6, 6, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 6, 6, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 6, 6, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 6, 6, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 6, 6, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 6, 6, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 6, 6, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 6, 6, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 6, 6, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 6, 6, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 6, 6, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 6, 6, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 6, 6, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 6, 6, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 6, 6, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 6, 6, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 6, 6, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 6, 6, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 6, 6, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 6, 6, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 6, 6, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 73728)        0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 73728)        0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Dense)                 (None, 6)            442374      dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 22,245,158\n",
            "Trainable params: 6,515,910\n",
            "Non-trainable params: 15,729,248\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcM7N7VoO32L"
      },
      "source": [
        "# pre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwFtvl9rO32M"
      },
      "source": [
        "# 將輸入圖片擴張\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1/255.,\n",
        "    width_shift_range=1.0,\n",
        "    height_shift_range=1.0,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    preprocessing_function=preprocess_input,\n",
        "    validation_split = 0.2\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsoDEQtZO32M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dd20771-6497-4268-b112-d468dd3459c1"
      },
      "source": [
        "# 產生迭代器\n",
        "img_itr_train = train_datagen.flow_from_directory(\n",
        "    './classify',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "img_itr_valid = train_datagen.flow_from_directory(\n",
        "    './classify',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4047 images belonging to 6 classes.\n",
            "Found 1009 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75A5GtDa3IuY"
      },
      "source": [
        "# Callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oio7Vb-j3JA6"
      },
      "source": [
        "from datetime import datetime\r\n",
        "\r\n",
        "model_dir = os.path.join(\r\n",
        "    'TL_InceptionV3',\r\n",
        "    datetime.now().strftime('%y%m%d_%H%M')\r\n",
        ")\r\n",
        "os.makedirs(model_dir, exist_ok=True)\r\n",
        "\r\n",
        "dir_weights = os.path.join(model_dir, 'weights')\r\n",
        "os.makedirs(dir_weights, exist_ok=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4PbZQb25iVo"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\r\n",
        "\r\n",
        "# ModelCheckpoint\r\n",
        "cp_filepath = os.path.join(dir_weights, 'ep_{epoch:02d}_ls_{val_categorical_accuracy:.2f}.h5')\r\n",
        "cp = ModelCheckpoint(\r\n",
        "    cp_filepath,\r\n",
        "    monitor='val_categorical_accuracy',\r\n",
        "    verbose=1,\r\n",
        "    save_best_only=True,\r\n",
        "    save_weights_only=False,\r\n",
        "    mode='auto',\r\n",
        "    save_freq='epoch'\r\n",
        ")\r\n",
        "\r\n",
        "# CSVLogger\r\n",
        "csv_filepath = os.path.join(model_dir, 'loss.csv')\r\n",
        "csv = CSVLogger(csv_filepath, append=True)\r\n",
        "\r\n",
        "# EarlyStopping\r\n",
        "estop = EarlyStopping(\r\n",
        "    monitor='val_categorical_accuracy',\r\n",
        "    # min_delta=0.0001,\r\n",
        "    patience=32, \r\n",
        "    verbose=1,\r\n",
        "    mode='auto'\r\n",
        "    # restore_best_weights=False\r\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BJQlYAoO32N"
      },
      "source": [
        "# Trainging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwKXCJTAO32P"
      },
      "source": [
        "import math\n",
        "\n",
        "# 計算幾個批次為一次學習\n",
        "batch_size = 64\n",
        "steps_per_epoch = math.ceil(\n",
        "    img_itr_train.samples/batch_size\n",
        ")\n",
        "validation_steps = math.ceil(\n",
        "    img_itr_valid.samples/batch_size\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg5465siO32P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1fc2443-278a-4087-f998-59bab72bb5c5"
      },
      "source": [
        "history = model.fit_generator(\n",
        "    img_itr_train,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=500,\n",
        "    validation_data=img_itr_valid,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=[cp, csv, estop]\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "64/64 [==============================] - 1507s 23s/step - loss: 1.8295 - categorical_accuracy: 0.4874 - val_loss: 1.4444 - val_categorical_accuracy: 0.2567\n",
            "\n",
            "Epoch 00001: val_categorical_accuracy improved from -inf to 0.25669, saving model to TL_InceptionV3/210120_0107/weights/ep_01_ls_0.26.h5\n",
            "Epoch 2/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.6225 - categorical_accuracy: 0.7630 - val_loss: 1.2047 - val_categorical_accuracy: 0.5629\n",
            "\n",
            "Epoch 00002: val_categorical_accuracy improved from 0.25669 to 0.56293, saving model to TL_InceptionV3/210120_0107/weights/ep_02_ls_0.56.h5\n",
            "Epoch 3/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.5593 - categorical_accuracy: 0.8012 - val_loss: 1.0402 - val_categorical_accuracy: 0.6373\n",
            "\n",
            "Epoch 00003: val_categorical_accuracy improved from 0.56293 to 0.63726, saving model to TL_InceptionV3/210120_0107/weights/ep_03_ls_0.64.h5\n",
            "Epoch 4/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.5552 - categorical_accuracy: 0.7955 - val_loss: 0.6278 - val_categorical_accuracy: 0.7830\n",
            "\n",
            "Epoch 00004: val_categorical_accuracy improved from 0.63726 to 0.78295, saving model to TL_InceptionV3/210120_0107/weights/ep_04_ls_0.78.h5\n",
            "Epoch 5/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.4924 - categorical_accuracy: 0.8155 - val_loss: 0.6616 - val_categorical_accuracy: 0.7602\n",
            "\n",
            "Epoch 00005: val_categorical_accuracy did not improve from 0.78295\n",
            "Epoch 6/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.4511 - categorical_accuracy: 0.8395 - val_loss: 0.5199 - val_categorical_accuracy: 0.8345\n",
            "\n",
            "Epoch 00006: val_categorical_accuracy improved from 0.78295 to 0.83449, saving model to TL_InceptionV3/210120_0107/weights/ep_06_ls_0.83.h5\n",
            "Epoch 7/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.4869 - categorical_accuracy: 0.8249 - val_loss: 0.4505 - val_categorical_accuracy: 0.8276\n",
            "\n",
            "Epoch 00007: val_categorical_accuracy did not improve from 0.83449\n",
            "Epoch 8/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.3555 - categorical_accuracy: 0.8606 - val_loss: 0.4480 - val_categorical_accuracy: 0.8494\n",
            "\n",
            "Epoch 00008: val_categorical_accuracy improved from 0.83449 to 0.84936, saving model to TL_InceptionV3/210120_0107/weights/ep_08_ls_0.85.h5\n",
            "Epoch 9/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.4089 - categorical_accuracy: 0.8507 - val_loss: 0.5690 - val_categorical_accuracy: 0.8018\n",
            "\n",
            "Epoch 00009: val_categorical_accuracy did not improve from 0.84936\n",
            "Epoch 10/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.4063 - categorical_accuracy: 0.8494 - val_loss: 0.3716 - val_categorical_accuracy: 0.8672\n",
            "\n",
            "Epoch 00010: val_categorical_accuracy improved from 0.84936 to 0.86720, saving model to TL_InceptionV3/210120_0107/weights/ep_10_ls_0.87.h5\n",
            "Epoch 11/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.3298 - categorical_accuracy: 0.8760 - val_loss: 0.3918 - val_categorical_accuracy: 0.8811\n",
            "\n",
            "Epoch 00011: val_categorical_accuracy improved from 0.86720 to 0.88107, saving model to TL_InceptionV3/210120_0107/weights/ep_11_ls_0.88.h5\n",
            "Epoch 12/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.3412 - categorical_accuracy: 0.8771 - val_loss: 0.4035 - val_categorical_accuracy: 0.8553\n",
            "\n",
            "Epoch 00012: val_categorical_accuracy did not improve from 0.88107\n",
            "Epoch 13/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.3818 - categorical_accuracy: 0.8592 - val_loss: 0.3822 - val_categorical_accuracy: 0.8603\n",
            "\n",
            "Epoch 00013: val_categorical_accuracy did not improve from 0.88107\n",
            "Epoch 14/500\n",
            "64/64 [==============================] - 71s 1s/step - loss: 0.3333 - categorical_accuracy: 0.8812 - val_loss: 0.4863 - val_categorical_accuracy: 0.8632\n",
            "\n",
            "Epoch 00014: val_categorical_accuracy did not improve from 0.88107\n",
            "Epoch 15/500\n",
            "64/64 [==============================] - 71s 1s/step - loss: 0.3285 - categorical_accuracy: 0.8860 - val_loss: 0.3860 - val_categorical_accuracy: 0.8741\n",
            "\n",
            "Epoch 00015: val_categorical_accuracy did not improve from 0.88107\n",
            "Epoch 16/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.3098 - categorical_accuracy: 0.8840 - val_loss: 0.3794 - val_categorical_accuracy: 0.8741\n",
            "\n",
            "Epoch 00016: val_categorical_accuracy did not improve from 0.88107\n",
            "Epoch 17/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.3176 - categorical_accuracy: 0.8844 - val_loss: 0.4374 - val_categorical_accuracy: 0.8008\n",
            "\n",
            "Epoch 00017: val_categorical_accuracy did not improve from 0.88107\n",
            "Epoch 18/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.3390 - categorical_accuracy: 0.8823 - val_loss: 0.3700 - val_categorical_accuracy: 0.8731\n",
            "\n",
            "Epoch 00018: val_categorical_accuracy did not improve from 0.88107\n",
            "Epoch 19/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.2752 - categorical_accuracy: 0.8924 - val_loss: 0.3400 - val_categorical_accuracy: 0.9029\n",
            "\n",
            "Epoch 00019: val_categorical_accuracy improved from 0.88107 to 0.90287, saving model to TL_InceptionV3/210120_0107/weights/ep_19_ls_0.90.h5\n",
            "Epoch 20/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.2808 - categorical_accuracy: 0.8941 - val_loss: 0.5334 - val_categorical_accuracy: 0.7879\n",
            "\n",
            "Epoch 00020: val_categorical_accuracy did not improve from 0.90287\n",
            "Epoch 21/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.3427 - categorical_accuracy: 0.8724 - val_loss: 0.4039 - val_categorical_accuracy: 0.8612\n",
            "\n",
            "Epoch 00021: val_categorical_accuracy did not improve from 0.90287\n",
            "Epoch 22/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.3193 - categorical_accuracy: 0.8819 - val_loss: 0.3674 - val_categorical_accuracy: 0.8781\n",
            "\n",
            "Epoch 00022: val_categorical_accuracy did not improve from 0.90287\n",
            "Epoch 23/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.2708 - categorical_accuracy: 0.8909 - val_loss: 0.3897 - val_categorical_accuracy: 0.8761\n",
            "\n",
            "Epoch 00023: val_categorical_accuracy did not improve from 0.90287\n",
            "Epoch 24/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.3069 - categorical_accuracy: 0.8854 - val_loss: 0.3975 - val_categorical_accuracy: 0.8593\n",
            "\n",
            "Epoch 00024: val_categorical_accuracy did not improve from 0.90287\n",
            "Epoch 25/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.2985 - categorical_accuracy: 0.8891 - val_loss: 0.4612 - val_categorical_accuracy: 0.8345\n",
            "\n",
            "Epoch 00025: val_categorical_accuracy did not improve from 0.90287\n",
            "Epoch 26/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.2796 - categorical_accuracy: 0.8975 - val_loss: 0.4569 - val_categorical_accuracy: 0.8048\n",
            "\n",
            "Epoch 00026: val_categorical_accuracy did not improve from 0.90287\n",
            "Epoch 27/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.3130 - categorical_accuracy: 0.8928 - val_loss: 0.3207 - val_categorical_accuracy: 0.8840\n",
            "\n",
            "Epoch 00027: val_categorical_accuracy did not improve from 0.90287\n",
            "Epoch 28/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.2388 - categorical_accuracy: 0.9110 - val_loss: 0.3846 - val_categorical_accuracy: 0.8811\n",
            "\n",
            "Epoch 00028: val_categorical_accuracy did not improve from 0.90287\n",
            "Epoch 29/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.2438 - categorical_accuracy: 0.9117 - val_loss: 0.3294 - val_categorical_accuracy: 0.8940\n",
            "\n",
            "Epoch 00029: val_categorical_accuracy did not improve from 0.90287\n",
            "Epoch 30/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.2733 - categorical_accuracy: 0.8996 - val_loss: 0.4303 - val_categorical_accuracy: 0.8831\n",
            "\n",
            "Epoch 00030: val_categorical_accuracy did not improve from 0.90287\n",
            "Epoch 31/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.2987 - categorical_accuracy: 0.8871 - val_loss: 0.5108 - val_categorical_accuracy: 0.8206\n",
            "\n",
            "Epoch 00031: val_categorical_accuracy did not improve from 0.90287\n",
            "Epoch 32/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.2657 - categorical_accuracy: 0.9080 - val_loss: 0.3125 - val_categorical_accuracy: 0.8989\n",
            "\n",
            "Epoch 00032: val_categorical_accuracy did not improve from 0.90287\n",
            "Epoch 33/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.2590 - categorical_accuracy: 0.9048 - val_loss: 0.4513 - val_categorical_accuracy: 0.8355\n",
            "\n",
            "Epoch 00033: val_categorical_accuracy did not improve from 0.90287\n",
            "Epoch 34/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.2690 - categorical_accuracy: 0.9039 - val_loss: 0.3862 - val_categorical_accuracy: 0.8573\n",
            "\n",
            "Epoch 00034: val_categorical_accuracy did not improve from 0.90287\n",
            "Epoch 35/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.2453 - categorical_accuracy: 0.9087 - val_loss: 0.5020 - val_categorical_accuracy: 0.7820\n",
            "\n",
            "Epoch 00035: val_categorical_accuracy did not improve from 0.90287\n",
            "Epoch 36/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.2432 - categorical_accuracy: 0.9068 - val_loss: 0.2946 - val_categorical_accuracy: 0.9118\n",
            "\n",
            "Epoch 00036: val_categorical_accuracy improved from 0.90287 to 0.91179, saving model to TL_InceptionV3/210120_0107/weights/ep_36_ls_0.91.h5\n",
            "Epoch 37/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.2347 - categorical_accuracy: 0.9157 - val_loss: 0.3104 - val_categorical_accuracy: 0.9049\n",
            "\n",
            "Epoch 00037: val_categorical_accuracy did not improve from 0.91179\n",
            "Epoch 38/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.2492 - categorical_accuracy: 0.9118 - val_loss: 0.3590 - val_categorical_accuracy: 0.8870\n",
            "\n",
            "Epoch 00038: val_categorical_accuracy did not improve from 0.91179\n",
            "Epoch 39/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.3091 - categorical_accuracy: 0.8866 - val_loss: 0.3272 - val_categorical_accuracy: 0.9049\n",
            "\n",
            "Epoch 00039: val_categorical_accuracy did not improve from 0.91179\n",
            "Epoch 40/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.2405 - categorical_accuracy: 0.9075 - val_loss: 0.3383 - val_categorical_accuracy: 0.8890\n",
            "\n",
            "Epoch 00040: val_categorical_accuracy did not improve from 0.91179\n",
            "Epoch 41/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.2431 - categorical_accuracy: 0.9132 - val_loss: 0.2968 - val_categorical_accuracy: 0.9029\n",
            "\n",
            "Epoch 00041: val_categorical_accuracy did not improve from 0.91179\n",
            "Epoch 42/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.2271 - categorical_accuracy: 0.9136 - val_loss: 0.3750 - val_categorical_accuracy: 0.8722\n",
            "\n",
            "Epoch 00042: val_categorical_accuracy did not improve from 0.91179\n",
            "Epoch 43/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.2165 - categorical_accuracy: 0.9188 - val_loss: 0.3056 - val_categorical_accuracy: 0.9128\n",
            "\n",
            "Epoch 00043: val_categorical_accuracy improved from 0.91179 to 0.91278, saving model to TL_InceptionV3/210120_0107/weights/ep_43_ls_0.91.h5\n",
            "Epoch 44/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.2360 - categorical_accuracy: 0.9202 - val_loss: 0.4419 - val_categorical_accuracy: 0.8226\n",
            "\n",
            "Epoch 00044: val_categorical_accuracy did not improve from 0.91278\n",
            "Epoch 45/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.2632 - categorical_accuracy: 0.9010 - val_loss: 0.3357 - val_categorical_accuracy: 0.9088\n",
            "\n",
            "Epoch 00045: val_categorical_accuracy did not improve from 0.91278\n",
            "Epoch 46/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.2373 - categorical_accuracy: 0.9124 - val_loss: 0.3063 - val_categorical_accuracy: 0.8949\n",
            "\n",
            "Epoch 00046: val_categorical_accuracy did not improve from 0.91278\n",
            "Epoch 47/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.1995 - categorical_accuracy: 0.9205 - val_loss: 0.2661 - val_categorical_accuracy: 0.9207\n",
            "\n",
            "Epoch 00047: val_categorical_accuracy improved from 0.91278 to 0.92071, saving model to TL_InceptionV3/210120_0107/weights/ep_47_ls_0.92.h5\n",
            "Epoch 48/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.2085 - categorical_accuracy: 0.9285 - val_loss: 0.2971 - val_categorical_accuracy: 0.8949\n",
            "\n",
            "Epoch 00048: val_categorical_accuracy did not improve from 0.92071\n",
            "Epoch 49/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.2045 - categorical_accuracy: 0.9275 - val_loss: 0.2579 - val_categorical_accuracy: 0.9158\n",
            "\n",
            "Epoch 00049: val_categorical_accuracy did not improve from 0.92071\n",
            "Epoch 50/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.2172 - categorical_accuracy: 0.9227 - val_loss: 0.3206 - val_categorical_accuracy: 0.8940\n",
            "\n",
            "Epoch 00050: val_categorical_accuracy did not improve from 0.92071\n",
            "Epoch 51/500\n",
            "64/64 [==============================] - 74s 1s/step - loss: 0.2557 - categorical_accuracy: 0.9074 - val_loss: 0.3184 - val_categorical_accuracy: 0.9148\n",
            "\n",
            "Epoch 00051: val_categorical_accuracy did not improve from 0.92071\n",
            "Epoch 52/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.2386 - categorical_accuracy: 0.9073 - val_loss: 0.3473 - val_categorical_accuracy: 0.8930\n",
            "\n",
            "Epoch 00052: val_categorical_accuracy did not improve from 0.92071\n",
            "Epoch 53/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.2374 - categorical_accuracy: 0.9180 - val_loss: 0.3824 - val_categorical_accuracy: 0.8573\n",
            "\n",
            "Epoch 00053: val_categorical_accuracy did not improve from 0.92071\n",
            "Epoch 54/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.2384 - categorical_accuracy: 0.9097 - val_loss: 0.2903 - val_categorical_accuracy: 0.9039\n",
            "\n",
            "Epoch 00054: val_categorical_accuracy did not improve from 0.92071\n",
            "Epoch 55/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.1870 - categorical_accuracy: 0.9308 - val_loss: 0.3577 - val_categorical_accuracy: 0.9078\n",
            "\n",
            "Epoch 00055: val_categorical_accuracy did not improve from 0.92071\n",
            "Epoch 56/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.2347 - categorical_accuracy: 0.9149 - val_loss: 0.3060 - val_categorical_accuracy: 0.9009\n",
            "\n",
            "Epoch 00056: val_categorical_accuracy did not improve from 0.92071\n",
            "Epoch 57/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.2538 - categorical_accuracy: 0.9061 - val_loss: 0.3718 - val_categorical_accuracy: 0.8801\n",
            "\n",
            "Epoch 00057: val_categorical_accuracy did not improve from 0.92071\n",
            "Epoch 58/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.2012 - categorical_accuracy: 0.9315 - val_loss: 0.3028 - val_categorical_accuracy: 0.9029\n",
            "\n",
            "Epoch 00058: val_categorical_accuracy did not improve from 0.92071\n",
            "Epoch 59/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.1949 - categorical_accuracy: 0.9223 - val_loss: 0.2951 - val_categorical_accuracy: 0.9118\n",
            "\n",
            "Epoch 00059: val_categorical_accuracy did not improve from 0.92071\n",
            "Epoch 60/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.1920 - categorical_accuracy: 0.9278 - val_loss: 0.4501 - val_categorical_accuracy: 0.8603\n",
            "\n",
            "Epoch 00060: val_categorical_accuracy did not improve from 0.92071\n",
            "Epoch 61/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.2380 - categorical_accuracy: 0.9134 - val_loss: 0.2531 - val_categorical_accuracy: 0.9306\n",
            "\n",
            "Epoch 00061: val_categorical_accuracy improved from 0.92071 to 0.93062, saving model to TL_InceptionV3/210120_0107/weights/ep_61_ls_0.93.h5\n",
            "Epoch 62/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.1803 - categorical_accuracy: 0.9347 - val_loss: 0.2858 - val_categorical_accuracy: 0.8900\n",
            "\n",
            "Epoch 00062: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 63/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.2148 - categorical_accuracy: 0.9204 - val_loss: 0.4544 - val_categorical_accuracy: 0.8404\n",
            "\n",
            "Epoch 00063: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 64/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.2350 - categorical_accuracy: 0.9116 - val_loss: 0.2858 - val_categorical_accuracy: 0.9177\n",
            "\n",
            "Epoch 00064: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 65/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.2029 - categorical_accuracy: 0.9234 - val_loss: 0.3037 - val_categorical_accuracy: 0.8969\n",
            "\n",
            "Epoch 00065: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 66/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.2210 - categorical_accuracy: 0.9231 - val_loss: 0.4072 - val_categorical_accuracy: 0.8503\n",
            "\n",
            "Epoch 00066: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 67/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.2642 - categorical_accuracy: 0.9082 - val_loss: 0.4436 - val_categorical_accuracy: 0.8236\n",
            "\n",
            "Epoch 00067: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 68/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1828 - categorical_accuracy: 0.9285 - val_loss: 0.2402 - val_categorical_accuracy: 0.9227\n",
            "\n",
            "Epoch 00068: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 69/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1972 - categorical_accuracy: 0.9296 - val_loss: 0.2748 - val_categorical_accuracy: 0.9197\n",
            "\n",
            "Epoch 00069: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 70/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1695 - categorical_accuracy: 0.9337 - val_loss: 0.2970 - val_categorical_accuracy: 0.8989\n",
            "\n",
            "Epoch 00070: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 71/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1973 - categorical_accuracy: 0.9218 - val_loss: 0.3834 - val_categorical_accuracy: 0.8533\n",
            "\n",
            "Epoch 00071: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 72/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.1945 - categorical_accuracy: 0.9294 - val_loss: 0.2947 - val_categorical_accuracy: 0.9167\n",
            "\n",
            "Epoch 00072: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 73/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.1814 - categorical_accuracy: 0.9339 - val_loss: 0.2337 - val_categorical_accuracy: 0.9247\n",
            "\n",
            "Epoch 00073: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 74/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.1848 - categorical_accuracy: 0.9311 - val_loss: 0.2941 - val_categorical_accuracy: 0.9207\n",
            "\n",
            "Epoch 00074: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 75/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1980 - categorical_accuracy: 0.9293 - val_loss: 0.3468 - val_categorical_accuracy: 0.8781\n",
            "\n",
            "Epoch 00075: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 76/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.1907 - categorical_accuracy: 0.9295 - val_loss: 0.2975 - val_categorical_accuracy: 0.9158\n",
            "\n",
            "Epoch 00076: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 77/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.1885 - categorical_accuracy: 0.9283 - val_loss: 0.2658 - val_categorical_accuracy: 0.9207\n",
            "\n",
            "Epoch 00077: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 78/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.1955 - categorical_accuracy: 0.9281 - val_loss: 0.2867 - val_categorical_accuracy: 0.9148\n",
            "\n",
            "Epoch 00078: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 79/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.1962 - categorical_accuracy: 0.9286 - val_loss: 0.2449 - val_categorical_accuracy: 0.9227\n",
            "\n",
            "Epoch 00079: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 80/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.1904 - categorical_accuracy: 0.9319 - val_loss: 0.3595 - val_categorical_accuracy: 0.8731\n",
            "\n",
            "Epoch 00080: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 81/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.1937 - categorical_accuracy: 0.9306 - val_loss: 0.2917 - val_categorical_accuracy: 0.9058\n",
            "\n",
            "Epoch 00081: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 82/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.2290 - categorical_accuracy: 0.9183 - val_loss: 0.3149 - val_categorical_accuracy: 0.8989\n",
            "\n",
            "Epoch 00082: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 83/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.1687 - categorical_accuracy: 0.9423 - val_loss: 0.2744 - val_categorical_accuracy: 0.9088\n",
            "\n",
            "Epoch 00083: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 84/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.1666 - categorical_accuracy: 0.9363 - val_loss: 0.2799 - val_categorical_accuracy: 0.9217\n",
            "\n",
            "Epoch 00084: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 85/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.1871 - categorical_accuracy: 0.9300 - val_loss: 0.3735 - val_categorical_accuracy: 0.8850\n",
            "\n",
            "Epoch 00085: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 86/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.1555 - categorical_accuracy: 0.9470 - val_loss: 0.3398 - val_categorical_accuracy: 0.8900\n",
            "\n",
            "Epoch 00086: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 87/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1825 - categorical_accuracy: 0.9303 - val_loss: 0.2704 - val_categorical_accuracy: 0.9207\n",
            "\n",
            "Epoch 00087: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 88/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1915 - categorical_accuracy: 0.9308 - val_loss: 0.2909 - val_categorical_accuracy: 0.9078\n",
            "\n",
            "Epoch 00088: val_categorical_accuracy did not improve from 0.93062\n",
            "Epoch 89/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1869 - categorical_accuracy: 0.9373 - val_loss: 0.2470 - val_categorical_accuracy: 0.9376\n",
            "\n",
            "Epoch 00089: val_categorical_accuracy improved from 0.93062 to 0.93756, saving model to TL_InceptionV3/210120_0107/weights/ep_89_ls_0.94.h5\n",
            "Epoch 90/500\n",
            "64/64 [==============================] - 73s 1s/step - loss: 0.1797 - categorical_accuracy: 0.9355 - val_loss: 0.2672 - val_categorical_accuracy: 0.9049\n",
            "\n",
            "Epoch 00090: val_categorical_accuracy did not improve from 0.93756\n",
            "Epoch 91/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1624 - categorical_accuracy: 0.9426 - val_loss: 0.2650 - val_categorical_accuracy: 0.9326\n",
            "\n",
            "Epoch 00091: val_categorical_accuracy did not improve from 0.93756\n",
            "Epoch 92/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1709 - categorical_accuracy: 0.9392 - val_loss: 0.2628 - val_categorical_accuracy: 0.9356\n",
            "\n",
            "Epoch 00092: val_categorical_accuracy did not improve from 0.93756\n",
            "Epoch 93/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1552 - categorical_accuracy: 0.9495 - val_loss: 0.2143 - val_categorical_accuracy: 0.9296\n",
            "\n",
            "Epoch 00093: val_categorical_accuracy did not improve from 0.93756\n",
            "Epoch 94/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1706 - categorical_accuracy: 0.9392 - val_loss: 0.2508 - val_categorical_accuracy: 0.9167\n",
            "\n",
            "Epoch 00094: val_categorical_accuracy did not improve from 0.93756\n",
            "Epoch 95/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1483 - categorical_accuracy: 0.9418 - val_loss: 0.3289 - val_categorical_accuracy: 0.8989\n",
            "\n",
            "Epoch 00095: val_categorical_accuracy did not improve from 0.93756\n",
            "Epoch 96/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1714 - categorical_accuracy: 0.9370 - val_loss: 0.2697 - val_categorical_accuracy: 0.9336\n",
            "\n",
            "Epoch 00096: val_categorical_accuracy did not improve from 0.93756\n",
            "Epoch 97/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.2099 - categorical_accuracy: 0.9204 - val_loss: 0.2573 - val_categorical_accuracy: 0.9177\n",
            "\n",
            "Epoch 00097: val_categorical_accuracy did not improve from 0.93756\n",
            "Epoch 98/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1562 - categorical_accuracy: 0.9444 - val_loss: 0.3428 - val_categorical_accuracy: 0.8870\n",
            "\n",
            "Epoch 00098: val_categorical_accuracy did not improve from 0.93756\n",
            "Epoch 99/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1892 - categorical_accuracy: 0.9278 - val_loss: 0.2556 - val_categorical_accuracy: 0.9267\n",
            "\n",
            "Epoch 00099: val_categorical_accuracy did not improve from 0.93756\n",
            "Epoch 100/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1632 - categorical_accuracy: 0.9479 - val_loss: 0.2883 - val_categorical_accuracy: 0.9108\n",
            "\n",
            "Epoch 00100: val_categorical_accuracy did not improve from 0.93756\n",
            "Epoch 101/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1343 - categorical_accuracy: 0.9517 - val_loss: 0.2168 - val_categorical_accuracy: 0.9336\n",
            "\n",
            "Epoch 00101: val_categorical_accuracy did not improve from 0.93756\n",
            "Epoch 102/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1457 - categorical_accuracy: 0.9463 - val_loss: 0.2856 - val_categorical_accuracy: 0.9158\n",
            "\n",
            "Epoch 00102: val_categorical_accuracy did not improve from 0.93756\n",
            "Epoch 103/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1404 - categorical_accuracy: 0.9524 - val_loss: 0.3009 - val_categorical_accuracy: 0.9148\n",
            "\n",
            "Epoch 00103: val_categorical_accuracy did not improve from 0.93756\n",
            "Epoch 104/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1749 - categorical_accuracy: 0.9385 - val_loss: 0.2732 - val_categorical_accuracy: 0.9128\n",
            "\n",
            "Epoch 00104: val_categorical_accuracy did not improve from 0.93756\n",
            "Epoch 105/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.2089 - categorical_accuracy: 0.9238 - val_loss: 0.2790 - val_categorical_accuracy: 0.9217\n",
            "\n",
            "Epoch 00105: val_categorical_accuracy did not improve from 0.93756\n",
            "Epoch 106/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1369 - categorical_accuracy: 0.9452 - val_loss: 0.2864 - val_categorical_accuracy: 0.9237\n",
            "\n",
            "Epoch 00106: val_categorical_accuracy did not improve from 0.93756\n",
            "Epoch 107/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1544 - categorical_accuracy: 0.9404 - val_loss: 0.3704 - val_categorical_accuracy: 0.8741\n",
            "\n",
            "Epoch 00107: val_categorical_accuracy did not improve from 0.93756\n",
            "Epoch 108/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1610 - categorical_accuracy: 0.9389 - val_loss: 0.2532 - val_categorical_accuracy: 0.9346\n",
            "\n",
            "Epoch 00108: val_categorical_accuracy did not improve from 0.93756\n",
            "Epoch 109/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1569 - categorical_accuracy: 0.9486 - val_loss: 0.2723 - val_categorical_accuracy: 0.9277\n",
            "\n",
            "Epoch 00109: val_categorical_accuracy did not improve from 0.93756\n",
            "Epoch 110/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1539 - categorical_accuracy: 0.9402 - val_loss: 0.2425 - val_categorical_accuracy: 0.9277\n",
            "\n",
            "Epoch 00110: val_categorical_accuracy did not improve from 0.93756\n",
            "Epoch 111/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1439 - categorical_accuracy: 0.9514 - val_loss: 0.2756 - val_categorical_accuracy: 0.9148\n",
            "\n",
            "Epoch 00111: val_categorical_accuracy did not improve from 0.93756\n",
            "Epoch 112/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1646 - categorical_accuracy: 0.9397 - val_loss: 0.3315 - val_categorical_accuracy: 0.8989\n",
            "\n",
            "Epoch 00112: val_categorical_accuracy did not improve from 0.93756\n",
            "Epoch 113/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1415 - categorical_accuracy: 0.9487 - val_loss: 0.2944 - val_categorical_accuracy: 0.9138\n",
            "\n",
            "Epoch 00113: val_categorical_accuracy did not improve from 0.93756\n",
            "Epoch 114/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1730 - categorical_accuracy: 0.9373 - val_loss: 0.3787 - val_categorical_accuracy: 0.8543\n",
            "\n",
            "Epoch 00114: val_categorical_accuracy did not improve from 0.93756\n",
            "Epoch 115/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1627 - categorical_accuracy: 0.9358 - val_loss: 0.2383 - val_categorical_accuracy: 0.9445\n",
            "\n",
            "Epoch 00115: val_categorical_accuracy improved from 0.93756 to 0.94450, saving model to TL_InceptionV3/210120_0107/weights/ep_115_ls_0.94.h5\n",
            "Epoch 116/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1384 - categorical_accuracy: 0.9517 - val_loss: 0.3144 - val_categorical_accuracy: 0.9049\n",
            "\n",
            "Epoch 00116: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 117/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1621 - categorical_accuracy: 0.9375 - val_loss: 0.3713 - val_categorical_accuracy: 0.8900\n",
            "\n",
            "Epoch 00117: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 118/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1644 - categorical_accuracy: 0.9455 - val_loss: 0.3043 - val_categorical_accuracy: 0.9197\n",
            "\n",
            "Epoch 00118: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 119/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1738 - categorical_accuracy: 0.9403 - val_loss: 0.2553 - val_categorical_accuracy: 0.9267\n",
            "\n",
            "Epoch 00119: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 120/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1714 - categorical_accuracy: 0.9396 - val_loss: 0.4487 - val_categorical_accuracy: 0.8622\n",
            "\n",
            "Epoch 00120: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 121/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1959 - categorical_accuracy: 0.9310 - val_loss: 0.2634 - val_categorical_accuracy: 0.9257\n",
            "\n",
            "Epoch 00121: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 122/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1538 - categorical_accuracy: 0.9406 - val_loss: 0.2488 - val_categorical_accuracy: 0.9356\n",
            "\n",
            "Epoch 00122: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 123/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1697 - categorical_accuracy: 0.9407 - val_loss: 0.2445 - val_categorical_accuracy: 0.9267\n",
            "\n",
            "Epoch 00123: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 124/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1341 - categorical_accuracy: 0.9523 - val_loss: 0.4231 - val_categorical_accuracy: 0.8434\n",
            "\n",
            "Epoch 00124: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 125/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1621 - categorical_accuracy: 0.9435 - val_loss: 0.3959 - val_categorical_accuracy: 0.8662\n",
            "\n",
            "Epoch 00125: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 126/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1469 - categorical_accuracy: 0.9460 - val_loss: 0.3222 - val_categorical_accuracy: 0.8999\n",
            "\n",
            "Epoch 00126: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 127/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1802 - categorical_accuracy: 0.9358 - val_loss: 0.3110 - val_categorical_accuracy: 0.9088\n",
            "\n",
            "Epoch 00127: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 128/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1499 - categorical_accuracy: 0.9479 - val_loss: 0.2891 - val_categorical_accuracy: 0.9177\n",
            "\n",
            "Epoch 00128: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 129/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1646 - categorical_accuracy: 0.9354 - val_loss: 0.3126 - val_categorical_accuracy: 0.8940\n",
            "\n",
            "Epoch 00129: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 130/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1799 - categorical_accuracy: 0.9305 - val_loss: 0.3859 - val_categorical_accuracy: 0.8573\n",
            "\n",
            "Epoch 00130: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 131/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1436 - categorical_accuracy: 0.9423 - val_loss: 0.5061 - val_categorical_accuracy: 0.7988\n",
            "\n",
            "Epoch 00131: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 132/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1456 - categorical_accuracy: 0.9428 - val_loss: 0.2864 - val_categorical_accuracy: 0.9158\n",
            "\n",
            "Epoch 00132: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 133/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1472 - categorical_accuracy: 0.9450 - val_loss: 0.2450 - val_categorical_accuracy: 0.9148\n",
            "\n",
            "Epoch 00133: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 134/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1537 - categorical_accuracy: 0.9431 - val_loss: 0.3543 - val_categorical_accuracy: 0.8920\n",
            "\n",
            "Epoch 00134: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 135/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1667 - categorical_accuracy: 0.9354 - val_loss: 0.2524 - val_categorical_accuracy: 0.9207\n",
            "\n",
            "Epoch 00135: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 136/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1404 - categorical_accuracy: 0.9467 - val_loss: 0.3445 - val_categorical_accuracy: 0.8692\n",
            "\n",
            "Epoch 00136: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 137/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1108 - categorical_accuracy: 0.9601 - val_loss: 0.2690 - val_categorical_accuracy: 0.9197\n",
            "\n",
            "Epoch 00137: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 138/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1176 - categorical_accuracy: 0.9567 - val_loss: 0.2394 - val_categorical_accuracy: 0.9425\n",
            "\n",
            "Epoch 00138: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 139/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1256 - categorical_accuracy: 0.9538 - val_loss: 0.2801 - val_categorical_accuracy: 0.9078\n",
            "\n",
            "Epoch 00139: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 140/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1303 - categorical_accuracy: 0.9534 - val_loss: 0.2709 - val_categorical_accuracy: 0.9237\n",
            "\n",
            "Epoch 00140: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 141/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1460 - categorical_accuracy: 0.9490 - val_loss: 0.2577 - val_categorical_accuracy: 0.9277\n",
            "\n",
            "Epoch 00141: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 142/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1311 - categorical_accuracy: 0.9551 - val_loss: 0.2273 - val_categorical_accuracy: 0.9395\n",
            "\n",
            "Epoch 00142: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 143/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1401 - categorical_accuracy: 0.9479 - val_loss: 0.3584 - val_categorical_accuracy: 0.8900\n",
            "\n",
            "Epoch 00143: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 144/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1466 - categorical_accuracy: 0.9482 - val_loss: 0.2495 - val_categorical_accuracy: 0.9306\n",
            "\n",
            "Epoch 00144: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 145/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1419 - categorical_accuracy: 0.9516 - val_loss: 0.5250 - val_categorical_accuracy: 0.8543\n",
            "\n",
            "Epoch 00145: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 146/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1534 - categorical_accuracy: 0.9476 - val_loss: 0.4753 - val_categorical_accuracy: 0.8276\n",
            "\n",
            "Epoch 00146: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 147/500\n",
            "64/64 [==============================] - 72s 1s/step - loss: 0.1601 - categorical_accuracy: 0.9365 - val_loss: 0.2775 - val_categorical_accuracy: 0.9177\n",
            "\n",
            "Epoch 00147: val_categorical_accuracy did not improve from 0.94450\n",
            "Epoch 00147: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWzAwLFQRZO-"
      },
      "source": [
        "model.save('InceptionV3.h5')\r\n",
        "\r\n",
        "from google.colab import files\r\n",
        "# files.download('Transfer_Training.h5')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHAXfDkDuH0X"
      },
      "source": [
        "# Review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpQ0_6xiO32P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "04a0a9e4-fd41-4f9c-e816-56787de7bd5b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history.history['loss']\n",
        "acc = history.history['categorical_accuracy']\n",
        "epochs = range(1, len(loss)+1)\n",
        "val_loss = history.history['val_loss']\n",
        "val_acc = history.history['val_categorical_accuracy']\n",
        "\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
        "ax[0].plot(epochs, loss, 'b', label='loss')\n",
        "ax[0].plot(epochs, val_loss, 'r', label='validation loss')\n",
        "ax[0].legend()\n",
        "ax[1].plot(epochs, acc, 'b', label='accuracy')\n",
        "ax[1].plot(epochs, val_acc, 'r', label='validation accuracy')\n",
        "ax[1].legend()\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc5L-ZvCuJyf"
      },
      "source": [
        "# Valid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3pubotFGOSA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5a20544-e588-4f89-b8c1-422c78619228"
      },
      "source": [
        "valid_datagen = ImageDataGenerator(\r\n",
        "    rescale=1./255,\r\n",
        "    preprocessing_function=preprocess_input\r\n",
        ")\r\n",
        "\r\n",
        "evaluate_itr = valid_datagen.flow_from_directory(\r\n",
        "    './classify',\r\n",
        "    target_size=(256, 256),\r\n",
        "    batch_size=64,\r\n",
        "    class_mode='categorical',\r\n",
        "    shuffle=False\r\n",
        ")\r\n",
        "\r\n",
        "loss, accuracy = model.evaluate_generator(evaluate_itr)\r\n",
        "print(f'loss = {loss:.2f}')\r\n",
        "print(f'accuracy = {accuracy:.2f}')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5056 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss = 0.32\n",
            "accuracy = 0.91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UH8sxiibApXm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00ae7803-80f7-4428-996c-e803bb7dd428"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "# labels\r\n",
        "labels = evaluate_itr.class_indices\r\n",
        "\r\n",
        "# then use predict_geneorator to predict the result base on model\r\n",
        "evaluate_itr.reset()\r\n",
        "pred = model.predict_generator(evaluate_itr, verbose=1)\r\n",
        "\r\n",
        "# prediction from model\r\n",
        "predicted_class_indices = np.argmax(pred, axis=1)\r\n",
        "# real results in training set\r\n",
        "true_label= evaluate_itr.classes"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 18s 218ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SASG2NmquPvr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "a575e4a5-9c0c-4294-eade-c7478ecd1bd1"
      },
      "source": [
        "#使用pd.crosstab来简单画出混淆矩阵\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "table = pd.crosstab(predicted_class_indices, true_label,colnames=['predict'], rownames=['label'])\r\n",
        "table"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>predict</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1124</td>\n",
              "      <td>14</td>\n",
              "      <td>44</td>\n",
              "      <td>23</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>51</td>\n",
              "      <td>928</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>132</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>171</td>\n",
              "      <td>38</td>\n",
              "      <td>24</td>\n",
              "      <td>719</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>395</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "predict     0    1    2    3    4     5\n",
              "label                                  \n",
              "0        1124   14   44   23    6     1\n",
              "1          51  928    0   14    5     1\n",
              "2           1    0  132    0    0     0\n",
              "3         171   38   24  719   74     0\n",
              "4           1    3    0    0  395     0\n",
              "5           0    1    0    0    0  1286"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}